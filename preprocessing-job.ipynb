{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Job\n",
    "\n",
    "In this notebook we will see how to run a pre-proccessing job for the speech commands datasets. The proccessing data set will take the the data from specific S3 bucket, then do the specified pre-proccessing, aftert that the prepoccessed data is saved again in the S3 bueckt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.session.Session().region_name\n",
    "\n",
    "role = get_execution_role()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utils/preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils/preprocessing.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "# Set the seed value for experiment reproducibility.\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "input_data_paths = \"/opt/ml/processing/input/data\"\n",
    "commands = np.array(tf.io.gfile.listdir(str(input_data_paths)))\n",
    "commands = commands[commands != 'README.md']\n",
    "print('Commands:', commands)\n",
    "\n",
    "def decode_audio(audio_binary):\n",
    "  # Decode WAV-encoded audio files to `float32` tensors, normalized\n",
    "  # to the [-1.0, 1.0] range. Return `float32` audio and a sample rate.\n",
    "  audio, _ = tf.audio.decode_wav(contents=audio_binary)\n",
    "  # Since all the data is single channel (mono), drop the `channels`\n",
    "  # axis from the array.\n",
    "  return tf.squeeze(audio, axis=-1)\n",
    "\n",
    "def get_label(file_path):\n",
    "  parts = tf.strings.split(\n",
    "      input=file_path,\n",
    "      sep=os.path.sep)\n",
    "  # Note: You'll use indexing here instead of tuple unpacking to enable this\n",
    "  # to work in a TensorFlow graph.\n",
    "  return parts[-2]\n",
    "\n",
    "def get_waveform_and_label(file_path):\n",
    "  label = get_label(file_path)\n",
    "  audio_binary = tf.io.read_file(file_path)\n",
    "  waveform = decode_audio(audio_binary)\n",
    "  return waveform, label\n",
    "\n",
    "def get_spectrogram(waveform):\n",
    "  # Zero-padding for an audio waveform with less than 16,000 samples.\n",
    "  input_len = 16000\n",
    "  waveform = waveform[:input_len]\n",
    "  zero_padding = tf.zeros(\n",
    "      [16000] - tf.shape(waveform),\n",
    "      dtype=tf.float32)\n",
    "  # Cast the waveform tensors' dtype to float32.\n",
    "  waveform = tf.cast(waveform, dtype=tf.float32)\n",
    "  # Concatenate the waveform with `zero_padding`, which ensures all audio\n",
    "  # clips are of the same length.\n",
    "  equal_length = tf.concat([waveform, zero_padding], 0)\n",
    "  # Convert the waveform to a spectrogram via a STFT.\n",
    "  spectrogram = tf.signal.stft(\n",
    "      equal_length, frame_length=255, frame_step=325, fft_length =78 )\n",
    "  # Obtain the magnitude of the STFT.\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "  # Add a `channels` dimension, so that the spectrogram can be used\n",
    "  # as image-like input data with convolution layers (which expect\n",
    "  # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "  spectrogram = spectrogram[..., tf.newaxis]\n",
    "  return spectrogram\n",
    "\n",
    "def get_spectrogram_and_label_id(audio, label):\n",
    "  spectrogram = get_spectrogram(audio)\n",
    "  label_id = tf.argmax(label == commands)\n",
    "  return spectrogram, label_id\n",
    "\n",
    "def preprocess_dataset(files):\n",
    "  files_ds = tf.data.Dataset.from_tensor_slices(files)\n",
    "  output_ds = files_ds.map(\n",
    "      map_func=get_waveform_and_label,\n",
    "      num_parallel_calls=AUTOTUNE)\n",
    "  output_ds = output_ds.map(\n",
    "      map_func=get_spectrogram_and_label_id,\n",
    "      num_parallel_calls=AUTOTUNE)\n",
    "  return output_ds\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--train-ratio\", type=float, default=0.8)\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    print(\"Received arguments {}\".format(args))\n",
    "    \n",
    "    \n",
    "    filenames = tf.io.gfile.glob(str(input_data_paths) + '/*/*')\n",
    "    filenames = tf.random.shuffle(filenames)\n",
    "    num_samples = len(filenames)\n",
    "    print('Number of total examples:', num_samples)\n",
    "#     print('Number of examples per label:',\n",
    "#           len(tf.io.gfile.listdir(str(input_data_paths/commands[1]))))\n",
    "    print('Example file tensor:', filenames[0])\n",
    "    \n",
    "    # splitting the data set depending on the training ratio\n",
    "    \n",
    "    train_ratio = args.train_ratio\n",
    "    val_test_ratio = (1 - train_ratio)/2\n",
    "    \n",
    "    train_files = filenames[:int(train_ratio*len(filenames))]\n",
    "    val_files = filenames[int(train_ratio*len(filenames)): int(train_ratio*len(filenames)) + int(val_test_ratio*len(filenames))]\n",
    "    test_files = filenames[-int(val_test_ratio*len(filenames)):]\n",
    "\n",
    "    print('Training set size', len(train_files))\n",
    "    print('Validation set size', len(val_files))\n",
    "    print('Test set size', len(test_files))\n",
    "    \n",
    "    # Converting audio to spectrograms\n",
    "    train_ds = preprocess_dataset(train_files)\n",
    "    val_ds = preprocess_dataset(val_files)\n",
    "    test_ds = preprocess_dataset(test_files)\n",
    "    \n",
    "\n",
    "    train_features_output_path = \"/opt/ml/processing/train\"\n",
    "    val_features_output_path = \"/opt/ml/processing/val\"\n",
    "    test_features_output_path = \"/opt/ml/processing/test\"\n",
    "    labels_output_path = \"/opt/ml/processing/commands/commands\"\n",
    "\n",
    "    \n",
    "    print(\"Saving train spectrogram to {}\".format(train_features_output_path))\n",
    "    tf.data.experimental.save(train_ds, train_features_output_path)\n",
    "   \n",
    "    print(\"Saving val spectrogram to {}\".format(val_features_output_path))\n",
    "    tf.data.experimental.save(val_ds, val_features_output_path)\n",
    "    \n",
    "    print(\"Saving test spectrogram to {}\".format(test_features_output_path))\n",
    "    tf.data.experimental.save(test_ds, test_features_output_path)\n",
    "    \n",
    "    print(\"Saving labels to {}\".format(labels_output_path))\n",
    "    np.save(labels_output_path, commands)\n",
    "    \n",
    "    \n",
    "    d = np.load(labels_output_path + \".npy\")\n",
    "    print(commands == d)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running training job for mini-data-set\n",
    "# Before running the job let's see where is the data that will be processed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Objects: 1000\n",
      "Total Objects: 1000\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/yes/ --recursive --summarize | grep \"Total Objects:\"\n",
    "! aws s3 ls s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/no/ --recursive --summarize | grep \"Total Objects:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will run preprocessing job to run the previous script to the mini Speech Commands dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "script_processor = ScriptProcessor(\n",
    "    command=[\"python3\"],\n",
    "    image_uri=\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.6.2-cpu-py38-ubuntu20.04\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  tensorflow-training-2022-06-02-22-48-19-611\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/yes/', 'LocalPath': '/opt/ml/processing/input/data/yes/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/no/', 'LocalPath': '/opt/ml/processing/input/data/no/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-062044820001/tensorflow-training-2022-06-02-22-48-19-611/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train_data', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/pre-processed/train/', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'val_data', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/pre-processed/val/', 'LocalPath': '/opt/ml/processing/val', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test_data', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/pre-processed/test/', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'commands', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/pre-processed/commands', 'LocalPath': '/opt/ml/processing/commands', 'S3UploadMode': 'EndOfJob'}}]\n",
      "............................\u001b[34m2022-06-02 22:52:47.091895: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2022-06-02 22:52:47.092442: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2022-06-02 22:52:47.118386: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34mCommands: ['no' 'yes']\u001b[0m\n",
      "\u001b[34mReceived arguments Namespace(train_ratio=0.8)\u001b[0m\n",
      "\u001b[34m2022-06-02 22:52:48.620323: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2022-06-02 22:52:48.621235: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\u001b[0m\n",
      "\u001b[34mNumber of total examples: 2000\u001b[0m\n",
      "\u001b[34mExample file tensor: tf.Tensor(b'/opt/ml/processing/input/data/yes/5c8af87a_nohash_4.wav', shape=(), dtype=string)\u001b[0m\n",
      "\u001b[34mTraining set size 1600\u001b[0m\n",
      "\u001b[34mValidation set size 199\u001b[0m\n",
      "\u001b[34mTest set size 199\u001b[0m\n",
      "\u001b[34mSaving train spectrogram to /opt/ml/processing/train\u001b[0m\n",
      "\u001b[34m2022-06-02 22:52:49.069821: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\u001b[0m\n",
      "\u001b[34mSaving val spectrogram to /opt/ml/processing/val\u001b[0m\n",
      "\u001b[34mSaving test spectrogram to /opt/ml/processing/test\u001b[0m\n",
      "\u001b[34mSaving labels to /opt/ml/processing/commands/commands\u001b[0m\n",
      "\u001b[34m[ True  True]\u001b[0m\n",
      "\n",
      "{'ProcessingInputs': [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/yes/', 'LocalPath': '/opt/ml/processing/input/data/yes/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/no/', 'LocalPath': '/opt/ml/processing/input/data/no/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-062044820001/tensorflow-training-2022-06-02-22-48-19-611/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'train_data', 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/pre-processed/train/', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}, 'AppManaged': False}, {'OutputName': 'val_data', 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/pre-processed/val/', 'LocalPath': '/opt/ml/processing/val', 'S3UploadMode': 'EndOfJob'}, 'AppManaged': False}, {'OutputName': 'test_data', 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/pre-processed/test/', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}, 'AppManaged': False}, {'OutputName': 'commands', 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/pre-processed/commands', 'LocalPath': '/opt/ml/processing/commands', 'S3UploadMode': 'EndOfJob'}, 'AppManaged': False}]}, 'ProcessingJobName': 'tensorflow-training-2022-06-02-22-48-19-611', 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.xlarge', 'VolumeSizeInGB': 30}}, 'StoppingCondition': {'MaxRuntimeInSeconds': 86400}, 'AppSpecification': {'ImageUri': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.6.2-cpu-py38-ubuntu20.04', 'ContainerEntrypoint': ['python3', '/opt/ml/processing/input/code/preprocessing.py'], 'ContainerArguments': ['--train-ratio', '0.8']}, 'RoleArn': 'arn:aws:iam::062044820001:role/service-role/AmazonSageMaker-ExecutionRole-20220310T114636', 'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:062044820001:processing-job/tensorflow-training-2022-06-02-22-48-19-611', 'ProcessingJobStatus': 'Completed', 'ProcessingEndTime': datetime.datetime(2022, 6, 2, 22, 53, 4, 10000, tzinfo=tzlocal()), 'ProcessingStartTime': datetime.datetime(2022, 6, 2, 22, 52, 22, 752000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2022, 6, 2, 22, 53, 4, 408000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2022, 6, 2, 22, 48, 19, 968000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': 'f04a6dd3-b196-447d-83fa-bf753cb54003', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'f04a6dd3-b196-447d-83fa-bf753cb54003', 'content-type': 'application/x-amz-json-1.1', 'content-length': '3012', 'date': 'Thu, 02 Jun 2022 22:53:32 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "script_processor.run(\n",
    "    code=\"utils/preprocessing.py\",\n",
    "    inputs=[ProcessingInput(source=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/yes/\", destination=\"/opt/ml/processing/input/data/yes/\"),\n",
    "            ProcessingInput(source=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/no/\", destination=\"/opt/ml/processing/input/data/no/\")],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train_data\", source=\"/opt/ml/processing/train\", destination=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/pre-processed/train/\"),\n",
    "        ProcessingOutput(output_name=\"val_data\", source=\"/opt/ml/processing/val\", destination=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/pre-processed/val/\"),\n",
    "        ProcessingOutput(output_name=\"test_data\", source=\"/opt/ml/processing/test\", destination=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/pre-processed/test/\"),\n",
    "        ProcessingOutput(output_name=\"commands\", source=\"/opt/ml/processing/commands\", destination=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/pre-processed/commands\"),\n",
    "    ],\n",
    "    arguments=[\"--train-ratio\", \"0.8\"],\n",
    ")\n",
    "script_processor_job_description = script_processor.jobs[-1].describe()\n",
    "print(script_processor_job_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will run preprocessing job to run the previous script to the Original Speech Commands dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Objects: 4044\n",
      "Total Objects: 3940\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/yes/ --recursive --summarize | grep \"Total Objects:\"\n",
    "! aws s3 ls s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/no/ --recursive --summarize | grep \"Total Objects:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will run preprocessing job to run the previous script with the data in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "script_processor_original_ds = ScriptProcessor(\n",
    "    command=[\"python3\"],\n",
    "    image_uri=\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.6.2-cpu-py38-ubuntu20.04\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  tensorflow-training-2022-06-02-22-53-36-432\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/yes/', 'LocalPath': '/opt/ml/processing/input/data/yes/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/no/', 'LocalPath': '/opt/ml/processing/input/data/no/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-062044820001/tensorflow-training-2022-06-02-22-53-36-432/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train_data', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/train/', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'val_data', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/val/', 'LocalPath': '/opt/ml/processing/val', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test_data', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/test/', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'commands', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/commands', 'LocalPath': '/opt/ml/processing/commands', 'S3UploadMode': 'EndOfJob'}}]\n",
      "...................................\u001b[34m2022-06-02 22:59:17.448724: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2022-06-02 22:59:17.448859: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2022-06-02 22:59:17.474936: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34mCommands: ['no' 'yes']\u001b[0m\n",
      "\u001b[34mReceived arguments Namespace(train_ratio=0.8)\u001b[0m\n",
      "\u001b[34m2022-06-02 22:59:18.981106: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2022-06-02 22:59:18.981972: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\u001b[0m\n",
      "\u001b[34mNumber of total examples: 7984\u001b[0m\n",
      "\u001b[34mExample file tensor: tf.Tensor(b'/opt/ml/processing/input/data/yes/6565a81d_nohash_4.wav', shape=(), dtype=string)\u001b[0m\n",
      "\u001b[34mTraining set size 6387\u001b[0m\n",
      "\u001b[34mValidation set size 798\u001b[0m\n",
      "\u001b[34mTest set size 798\u001b[0m\n",
      "\u001b[34mSaving train spectrogram to /opt/ml/processing/train\u001b[0m\n",
      "\u001b[34m2022-06-02 22:59:19.433820: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\u001b[0m\n",
      "\u001b[34mSaving val spectrogram to /opt/ml/processing/val\u001b[0m\n",
      "\u001b[34mSaving test spectrogram to /opt/ml/processing/test\u001b[0m\n",
      "\u001b[34mSaving labels to /opt/ml/processing/commands/commands\u001b[0m\n",
      "\u001b[34m[ True  True]\u001b[0m\n",
      "\n",
      "{'ProcessingInputs': [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/yes/', 'LocalPath': '/opt/ml/processing/input/data/yes/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/no/', 'LocalPath': '/opt/ml/processing/input/data/no/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-062044820001/tensorflow-training-2022-06-02-22-53-36-432/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'train_data', 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/train/', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}, 'AppManaged': False}, {'OutputName': 'val_data', 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/val/', 'LocalPath': '/opt/ml/processing/val', 'S3UploadMode': 'EndOfJob'}, 'AppManaged': False}, {'OutputName': 'test_data', 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/test/', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}, 'AppManaged': False}, {'OutputName': 'commands', 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/commands', 'LocalPath': '/opt/ml/processing/commands', 'S3UploadMode': 'EndOfJob'}, 'AppManaged': False}]}, 'ProcessingJobName': 'tensorflow-training-2022-06-02-22-53-36-432', 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.xlarge', 'VolumeSizeInGB': 30}}, 'StoppingCondition': {'MaxRuntimeInSeconds': 86400}, 'AppSpecification': {'ImageUri': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.6.2-cpu-py38-ubuntu20.04', 'ContainerEntrypoint': ['python3', '/opt/ml/processing/input/code/preprocessing.py'], 'ContainerArguments': ['--train-ratio', '0.8']}, 'RoleArn': 'arn:aws:iam::062044820001:role/service-role/AmazonSageMaker-ExecutionRole-20220310T114636', 'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:062044820001:processing-job/tensorflow-training-2022-06-02-22-53-36-432', 'ProcessingJobStatus': 'Completed', 'ProcessingEndTime': datetime.datetime(2022, 6, 2, 22, 59, 39, 149000, tzinfo=tzlocal()), 'ProcessingStartTime': datetime.datetime(2022, 6, 2, 22, 57, 54, 891000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2022, 6, 2, 22, 59, 39, 532000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2022, 6, 2, 22, 53, 36, 688000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': '07631067-2537-4577-940f-3f29d79850d4', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '07631067-2537-4577-940f-3f29d79850d4', 'content-type': 'application/x-amz-json-1.1', 'content-length': '2983', 'date': 'Thu, 02 Jun 2022 23:00:20 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "script_processor_original_ds.run(\n",
    "    code=\"utils/preprocessing.py\",\n",
    "    inputs=[ProcessingInput(source=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/yes/\", destination=\"/opt/ml/processing/input/data/yes/\"),\n",
    "            ProcessingInput(source=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/no/\", destination=\"/opt/ml/processing/input/data/no/\")],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train_data\", source=\"/opt/ml/processing/train\", destination=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/train/\"),\n",
    "        ProcessingOutput(output_name=\"val_data\", source=\"/opt/ml/processing/val\", destination=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/val/\"),\n",
    "        ProcessingOutput(output_name=\"test_data\", source=\"/opt/ml/processing/test\", destination=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/test/\"),\n",
    "        ProcessingOutput(output_name=\"commands\", source=\"/opt/ml/processing/commands\", destination=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/commands\"),\n",
    "    ],\n",
    "    arguments=[\"--train-ratio\", \"0.8\"],\n",
    ")\n",
    "script_processor_job_description = script_processor_original_ds.jobs[-1].describe()\n",
    "print(script_processor_job_description)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.6-cpu-py38-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
