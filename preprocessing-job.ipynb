{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Job\n",
    "\n",
    "In this notebook we will see how to run a pre-proccessing job for the speech commands datasets. The proccessing data set will take the the data from specific S3 bucket, then do the specified pre-proccessing, aftert that the prepoccessed data is saved again in the S3 bueckt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.session.Session().region_name\n",
    "\n",
    "role = get_execution_role()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# before running the job let's see where in the data that will be processed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Objects: 4044\n",
      "Total Objects: 3940\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/yes/ --recursive --summarize | grep \"Total Objects:\"\n",
    "! aws s3 ls s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/no/ --recursive --summarize | grep \"Total Objects:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have mini-dataset saved in s3 bucket. Now we will start with writing the script that will be used by the pre-processing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utils/preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils/preprocessing.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "# Set the seed value for experiment reproducibility.\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "input_data_paths = \"/opt/ml/processing/input/data\"\n",
    "commands = np.array(tf.io.gfile.listdir(str(input_data_paths)))\n",
    "commands = commands[commands != 'README.md']\n",
    "print('Commands:', commands)\n",
    "\n",
    "def decode_audio(audio_binary):\n",
    "  # Decode WAV-encoded audio files to `float32` tensors, normalized\n",
    "  # to the [-1.0, 1.0] range. Return `float32` audio and a sample rate.\n",
    "  audio, _ = tf.audio.decode_wav(contents=audio_binary)\n",
    "  # Since all the data is single channel (mono), drop the `channels`\n",
    "  # axis from the array.\n",
    "  return tf.squeeze(audio, axis=-1)\n",
    "\n",
    "def get_label(file_path):\n",
    "  parts = tf.strings.split(\n",
    "      input=file_path,\n",
    "      sep=os.path.sep)\n",
    "  # Note: You'll use indexing here instead of tuple unpacking to enable this\n",
    "  # to work in a TensorFlow graph.\n",
    "  return parts[-2]\n",
    "\n",
    "def get_waveform_and_label(file_path):\n",
    "  label = get_label(file_path)\n",
    "  audio_binary = tf.io.read_file(file_path)\n",
    "  waveform = decode_audio(audio_binary)\n",
    "  return waveform, label\n",
    "\n",
    "def get_spectrogram(waveform):\n",
    "  # Zero-padding for an audio waveform with less than 16,000 samples.\n",
    "  input_len = 16000\n",
    "  waveform = waveform[:input_len]\n",
    "  zero_padding = tf.zeros(\n",
    "      [16000] - tf.shape(waveform),\n",
    "      dtype=tf.float32)\n",
    "  # Cast the waveform tensors' dtype to float32.\n",
    "  waveform = tf.cast(waveform, dtype=tf.float32)\n",
    "  # Concatenate the waveform with `zero_padding`, which ensures all audio\n",
    "  # clips are of the same length.\n",
    "  equal_length = tf.concat([waveform, zero_padding], 0)\n",
    "  # Convert the waveform to a spectrogram via a STFT.\n",
    "  spectrogram = tf.signal.stft(\n",
    "      equal_length, frame_length=255, frame_step=325, fft_length =78 )\n",
    "  # Obtain the magnitude of the STFT.\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "  # Add a `channels` dimension, so that the spectrogram can be used\n",
    "  # as image-like input data with convolution layers (which expect\n",
    "  # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "  spectrogram = spectrogram[..., tf.newaxis]\n",
    "  return spectrogram\n",
    "\n",
    "def get_spectrogram_and_label_id(audio, label):\n",
    "  spectrogram = get_spectrogram(audio)\n",
    "  label_id = tf.argmax(label == commands)\n",
    "  return spectrogram, label_id\n",
    "\n",
    "def preprocess_dataset(files):\n",
    "  files_ds = tf.data.Dataset.from_tensor_slices(files)\n",
    "  output_ds = files_ds.map(\n",
    "      map_func=get_waveform_and_label,\n",
    "      num_parallel_calls=AUTOTUNE)\n",
    "  output_ds = output_ds.map(\n",
    "      map_func=get_spectrogram_and_label_id,\n",
    "      num_parallel_calls=AUTOTUNE)\n",
    "  return output_ds\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--train-ratio\", type=float, default=0.8)\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    print(\"Received arguments {}\".format(args))\n",
    "    \n",
    "    \n",
    "    filenames = tf.io.gfile.glob(str(input_data_paths) + '/*/*')\n",
    "    filenames = tf.random.shuffle(filenames)\n",
    "    num_samples = len(filenames)\n",
    "    print('Number of total examples:', num_samples)\n",
    "#     print('Number of examples per label:',\n",
    "#           len(tf.io.gfile.listdir(str(input_data_paths/commands[1]))))\n",
    "    print('Example file tensor:', filenames[0])\n",
    "    \n",
    "    # splitting the data set depending on the training ratio\n",
    "    \n",
    "    train_ratio = args.train_ratio\n",
    "    val_test_ratio = (1 - train_ratio)/2\n",
    "    \n",
    "    train_files = filenames[:int(train_ratio*len(filenames))]\n",
    "    val_files = filenames[int(train_ratio*len(filenames)): int(train_ratio*len(filenames)) + int(val_test_ratio*len(filenames))]\n",
    "    test_files = filenames[-int(val_test_ratio*len(filenames)):]\n",
    "\n",
    "    print('Training set size', len(train_files))\n",
    "    print('Validation set size', len(val_files))\n",
    "    print('Test set size', len(test_files))\n",
    "    \n",
    "    # Converting audio to spectrograms\n",
    "    train_ds = preprocess_dataset(train_files)\n",
    "    val_ds = preprocess_dataset(val_files)\n",
    "    test_ds = preprocess_dataset(test_files)\n",
    "    \n",
    "\n",
    "    train_features_output_path = \"/opt/ml/processing/train\"\n",
    "    val_features_output_path = \"/opt/ml/processing/val\"\n",
    "    test_features_output_path = \"/opt/ml/processing/test\"\n",
    "    labels_output_path = \"/opt/ml/processing/commands/commands\"\n",
    "\n",
    "    \n",
    "    print(\"Saving train spectrogram to {}\".format(train_features_output_path))\n",
    "    tf.data.experimental.save(train_ds, train_features_output_path)\n",
    "   \n",
    "    print(\"Saving val spectrogram to {}\".format(val_features_output_path))\n",
    "    tf.data.experimental.save(val_ds, val_features_output_path)\n",
    "    \n",
    "    print(\"Saving test spectrogram to {}\".format(test_features_output_path))\n",
    "    tf.data.experimental.save(test_ds, test_features_output_path)\n",
    "    \n",
    "    print(\"Saving labels to {}\".format(labels_output_path))\n",
    "    np.save(labels_output_path, commands)\n",
    "    \n",
    "    \n",
    "    d = np.load(labels_output_path + \".npy\")\n",
    "    print(commands == d)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will run preprocessing job to run the previous script with the data in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "script_processor = ScriptProcessor(\n",
    "    command=[\"python3\"],\n",
    "    image_uri=\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.6.2-cpu-py38-ubuntu20.04\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  tensorflow-training-2022-05-10-21-34-47-652\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/yes/', 'LocalPath': '/opt/ml/processing/input/data/yes/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/no/', 'LocalPath': '/opt/ml/processing/input/data/no/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-062044820001/tensorflow-training-2022-05-10-21-34-47-652/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train_data', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/train/', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'val_data', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/val/', 'LocalPath': '/opt/ml/processing/val', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test_data', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/test/', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'commands', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/commands', 'LocalPath': '/opt/ml/processing/commands', 'S3UploadMode': 'EndOfJob'}}]\n",
      "..................................\u001b[34m2022-05-10 21:40:21.388432: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2022-05-10 21:40:21.388567: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2022-05-10 21:40:21.414657: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34mCommands: ['no' 'yes']\u001b[0m\n",
      "\u001b[34mReceived arguments Namespace(train_ratio=0.8)\u001b[0m\n",
      "\u001b[34m2022-05-10 21:40:23.040324: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2022-05-10 21:40:23.041290: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\u001b[0m\n",
      "\u001b[34mNumber of total examples: 7984\u001b[0m\n",
      "\u001b[34mExample file tensor: tf.Tensor(b'/opt/ml/processing/input/data/yes/55463c16_nohash_0.wav', shape=(), dtype=string)\u001b[0m\n",
      "\u001b[34mTraining set size 6387\u001b[0m\n",
      "\u001b[34mValidation set size 798\u001b[0m\n",
      "\u001b[34mTest set size 798\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/ml/processing/input/code/preprocessing.py\", line 118, in <module>\n",
      "    train_ds = preprocess_dataset(train_files)\n",
      "  File \"/opt/ml/processing/input/code/preprocessing.py\", line 82, in preprocess_dataset\n",
      "    output_ds = output_ds.map(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1863, in map\n",
      "    return ParallelMapDataset(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 5020, in __init__\n",
      "    self._map_func = StructuredFunctionWrapper(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4218, in __init__\n",
      "    self._function = fn_factory()\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3150, in get_concrete_function\n",
      "    graph_function = self._get_concrete_function_garbage_collected(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3116, in _get_concrete_function_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3463, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3298, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1007, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4195, in wrapped_fn\n",
      "    ret = wrapper_helper(*args)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4125, in wrapper_helper\n",
      "    ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 695, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\u001b[0m\n",
      "\u001b[34mTypeError: in user code:\n",
      "    /opt/ml/processing/input/code/preprocessing.py:73 get_spectrogram_and_label_id  *\n",
      "        spectrogram = get_spectrogram(audio)\n",
      "    /opt/ml/processing/input/code/preprocessing.py:62 get_spectrogram  *\n",
      "        spectrogram = tf.signal.stft(\n",
      "    /usr/local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper  **\n",
      "        return target(*args, **kwargs)\n",
      "    TypeError: stft() got multiple values for argument 'frame_length'\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Processing job tensorflow-training-2022-05-10-21-34-47-652: Failed. Reason: AlgorithmError: See job logs for more information",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-07488685d014>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProcessingInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProcessingOutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m script_processor.run(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utils/preprocessing.py\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     inputs=[ProcessingInput(source=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/yes/\", destination=\"/opt/ml/processing/input/data/yes/\"),\n\u001b[1;32m      5\u001b[0m             ProcessingInput(source=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/no/\", destination=\"/opt/ml/processing/input/data/no/\")],\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sagemaker/processing.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, code, inputs, outputs, arguments, wait, logs, job_name, experiment_config, kms_key)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_include_code_in_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sagemaker/processing.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    960\u001b[0m         \"\"\"\n\u001b[1;32m    961\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_processing_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_processing_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_processing_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   3868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3870\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ProcessingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3871\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3872\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3331\u001b[0m             \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FailureReason\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"(No reason provided)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3332\u001b[0m             \u001b[0mjob_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatus_key_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"JobStatus\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" job\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3333\u001b[0;31m             raise exceptions.UnexpectedStatusException(\n\u001b[0m\u001b[1;32m   3334\u001b[0m                 message=\"Error for {job_type} {job_name}: {status}. Reason: {reason}\".format(\n\u001b[1;32m   3335\u001b[0m                     \u001b[0mjob_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Processing job tensorflow-training-2022-05-10-21-34-47-652: Failed. Reason: AlgorithmError: See job logs for more information"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "script_processor.run(\n",
    "    code=\"utils/preprocessing.py\",\n",
    "    inputs=[ProcessingInput(source=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/yes/\", destination=\"/opt/ml/processing/input/data/yes/\"),\n",
    "            ProcessingInput(source=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/no/\", destination=\"/opt/ml/processing/input/data/no/\")],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train_data\", source=\"/opt/ml/processing/train\", destination=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/pre-processed/train/\"),\n",
    "        ProcessingOutput(output_name=\"val_data\", source=\"/opt/ml/processing/val\", destination=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/pre-processed/val/\"),\n",
    "        ProcessingOutput(output_name=\"test_data\", source=\"/opt/ml/processing/test\", destination=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/pre-processed/test/\"),\n",
    "        ProcessingOutput(output_name=\"commands\", source=\"/opt/ml/processing/commands\", destination=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/mini-speech-commands/pre-processed/commands\"),\n",
    "    ],\n",
    "    arguments=[\"--train-ratio\", \"0.8\"],\n",
    ")\n",
    "script_processor_job_description = script_processor.jobs[-1].describe()\n",
    "print(script_processor_job_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the pre-processing job on the Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Objects: 4044\n",
      "Total Objects: 3940\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/yes/ --recursive --summarize | grep \"Total Objects:\"\n",
    "! aws s3 ls s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/no/ --recursive --summarize | grep \"Total Objects:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will run preprocessing job to run the previous script with the data in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "script_processor_original_ds = ScriptProcessor(\n",
    "    command=[\"python3\"],\n",
    "    image_uri=\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.6.2-cpu-py38-ubuntu20.04\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  tensorflow-training-2022-05-10-21-43-03-944\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/yes/', 'LocalPath': '/opt/ml/processing/input/data/yes/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/no/', 'LocalPath': '/opt/ml/processing/input/data/no/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-062044820001/tensorflow-training-2022-05-10-21-43-03-944/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train_data', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/train/', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'val_data', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/val/', 'LocalPath': '/opt/ml/processing/val', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test_data', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/test/', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'commands', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/commands', 'LocalPath': '/opt/ml/processing/commands', 'S3UploadMode': 'EndOfJob'}}]\n",
      "................................\u001b[34m2022-05-10 21:48:13.263016: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2022-05-10 21:48:13.263138: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2022-05-10 21:48:13.288909: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34mCommands: ['no' 'yes']\u001b[0m\n",
      "\u001b[34mReceived arguments Namespace(train_ratio=0.8)\u001b[0m\n",
      "\u001b[34m2022-05-10 21:48:14.869744: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2022-05-10 21:48:14.870689: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\u001b[0m\n",
      "\u001b[34mNumber of total examples: 7984\u001b[0m\n",
      "\u001b[34mExample file tensor: tf.Tensor(b'/opt/ml/processing/input/data/yes/3e31dffe_nohash_0.wav', shape=(), dtype=string)\u001b[0m\n",
      "\u001b[34mTraining set size 6387\u001b[0m\n",
      "\u001b[34mValidation set size 798\u001b[0m\n",
      "\u001b[34mTest set size 798\u001b[0m\n",
      "\u001b[34mSaving train spectrogram to /opt/ml/processing/train\u001b[0m\n",
      "\u001b[34m2022-05-10 21:48:15.320376: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\u001b[0m\n",
      "\n",
      "\u001b[34mSaving val spectrogram to /opt/ml/processing/val\u001b[0m\n",
      "\u001b[34mSaving test spectrogram to /opt/ml/processing/test\u001b[0m\n",
      "\u001b[34mSaving labels to /opt/ml/processing/commands/commands\u001b[0m\n",
      "\u001b[34m[ True  True]\u001b[0m\n",
      "{'ProcessingInputs': [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/yes/', 'LocalPath': '/opt/ml/processing/input/data/yes/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/no/', 'LocalPath': '/opt/ml/processing/input/data/no/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-062044820001/tensorflow-training-2022-05-10-21-43-03-944/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'train_data', 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/train/', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}, 'AppManaged': False}, {'OutputName': 'val_data', 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/val/', 'LocalPath': '/opt/ml/processing/val', 'S3UploadMode': 'EndOfJob'}, 'AppManaged': False}, {'OutputName': 'test_data', 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/test/', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}, 'AppManaged': False}, {'OutputName': 'commands', 'S3Output': {'S3Uri': 's3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/commands', 'LocalPath': '/opt/ml/processing/commands', 'S3UploadMode': 'EndOfJob'}, 'AppManaged': False}]}, 'ProcessingJobName': 'tensorflow-training-2022-05-10-21-43-03-944', 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.xlarge', 'VolumeSizeInGB': 30}}, 'StoppingCondition': {'MaxRuntimeInSeconds': 86400}, 'AppSpecification': {'ImageUri': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.6.2-cpu-py38-ubuntu20.04', 'ContainerEntrypoint': ['python3', '/opt/ml/processing/input/code/preprocessing.py'], 'ContainerArguments': ['--train-ratio', '0.8']}, 'RoleArn': 'arn:aws:iam::062044820001:role/service-role/AmazonSageMaker-ExecutionRole-20220310T114636', 'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:062044820001:processing-job/tensorflow-training-2022-05-10-21-43-03-944', 'ProcessingJobStatus': 'Completed', 'ProcessingEndTime': datetime.datetime(2022, 5, 10, 21, 48, 34, 966000, tzinfo=tzlocal()), 'ProcessingStartTime': datetime.datetime(2022, 5, 10, 21, 47, 2, 863000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2022, 5, 10, 21, 48, 35, 365000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2022, 5, 10, 21, 43, 4, 225000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': '9e47554c-1f41-4988-bc71-283c6a3f21f3', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '9e47554c-1f41-4988-bc71-283c6a3f21f3', 'content-type': 'application/x-amz-json-1.1', 'content-length': '2983', 'date': 'Tue, 10 May 2022 21:48:46 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "script_processor_original_ds.run(\n",
    "    code=\"utils/preprocessing.py\",\n",
    "    inputs=[ProcessingInput(source=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/yes/\", destination=\"/opt/ml/processing/input/data/yes/\"),\n",
    "            ProcessingInput(source=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/no/\", destination=\"/opt/ml/processing/input/data/no/\")],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train_data\", source=\"/opt/ml/processing/train\", destination=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/train/\"),\n",
    "        ProcessingOutput(output_name=\"val_data\", source=\"/opt/ml/processing/val\", destination=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/val/\"),\n",
    "        ProcessingOutput(output_name=\"test_data\", source=\"/opt/ml/processing/test\", destination=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/test/\"),\n",
    "        ProcessingOutput(output_name=\"commands\", source=\"/opt/ml/processing/commands\", destination=\"s3://sagemaker-studio-062044820001-7qbctb3w94p/Datasets/speech-commands/pre-processed/commands\"),\n",
    "    ],\n",
    "    arguments=[\"--train-ratio\", \"0.8\"],\n",
    ")\n",
    "script_processor_job_description = script_processor_original_ds.jobs[-1].describe()\n",
    "print(script_processor_job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.6-cpu-py38-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
