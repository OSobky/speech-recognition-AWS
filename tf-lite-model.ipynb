{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaVtYN4nlCft"
   },
   "source": [
    "## In this Notebook, We will convert the model artifact to a TF lite model \n",
    "### Which is a nessecry step to deploy the model on the PSoC 6 board \n",
    "\n",
    "## Configure Defaults\n",
    "\n",
    "**MODIFY** the following constants for your specific use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/site-packages (from -r utils/keras_rewrite/requirements.txt (line 1)) (2.6.2)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/site-packages (from -r utils/keras_rewrite/requirements.txt (line 2)) (2.6.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/site-packages (from -r utils/keras_rewrite/requirements.txt (line 3)) (1.19.5)\n",
      "Requirement already satisfied: mlflow in /usr/local/lib/python3.8/site-packages (from -r utils/keras_rewrite/requirements.txt (line 4)) (1.26.1)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.8/site-packages (from -r utils/keras_rewrite/requirements.txt (line 5)) (1.20.22)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/site-packages (from -r utils/keras_rewrite/requirements.txt (line 6)) (4.62.3)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.8/site-packages (from -r utils/keras_rewrite/requirements.txt (line 7)) (0.20.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.8/site-packages (from tensorflow->-r utils/keras_rewrite/requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.8/site-packages (from tensorflow->-r utils/keras_rewrite/requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.8/site-packages (from tensorflow->-r utils/keras_rewrite/requirements.txt (line 1)) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.8/site-packages (from tensorflow->-r utils/keras_rewrite/requirements.txt (line 1)) (3.7.4.3)\n",
      "Requirement already satisfied: keras<2.7,>=2.6.0 in /usr/local/lib/python3.8/site-packages (from tensorflow->-r utils/keras_rewrite/requirements.txt (line 1)) (2.6.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.8/site-packages (from tensorflow->-r utils/keras_rewrite/requirements.txt (line 1)) (1.12)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.8/site-packages (from tensorflow->-r utils/keras_rewrite/requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.8/site-packages (from tensorflow->-r utils/keras_rewrite/requirements.txt (line 1)) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.8/site-packages (from tensorflow->-r utils/keras_rewrite/requirements.txt (line 1)) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/site-packages (from tensorflow->-r utils/keras_rewrite/requirements.txt (line 1)) (3.19.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /usr/local/lib/python3.8/site-packages (from tensorflow->-r utils/keras_rewrite/requirements.txt (line 1)) (2.6.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.8/site-packages (from tensorflow->-r utils/keras_rewrite/requirements.txt (line 1)) (1.1.2)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.8/site-packages (from tensorflow->-r utils/keras_rewrite/requirements.txt (line 1)) (0.10.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.8/site-packages (from tensorflow->-r utils/keras_rewrite/requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.8/site-packages (from tensorflow->-r utils/keras_rewrite/requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.8/site-packages (from tensorflow->-r utils/keras_rewrite/requirements.txt (line 1)) (0.37.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.8/site-packages (from tensorflow->-r utils/keras_rewrite/requirements.txt (line 1)) (1.42.0)\n",
      "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.8/site-packages (from tensorflow->-r utils/keras_rewrite/requirements.txt (line 1)) (5.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/site-packages (from tensorboard->-r utils/keras_rewrite/requirements.txt (line 2)) (0.4.6)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.8/site-packages (from tensorboard->-r utils/keras_rewrite/requirements.txt (line 2)) (1.35.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/site-packages (from tensorboard->-r utils/keras_rewrite/requirements.txt (line 2)) (2.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/site-packages (from tensorboard->-r utils/keras_rewrite/requirements.txt (line 2)) (2.24.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/site-packages (from tensorboard->-r utils/keras_rewrite/requirements.txt (line 2)) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/site-packages (from tensorboard->-r utils/keras_rewrite/requirements.txt (line 2)) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/site-packages (from tensorboard->-r utils/keras_rewrite/requirements.txt (line 2)) (59.5.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/site-packages (from tensorboard->-r utils/keras_rewrite/requirements.txt (line 2)) (3.3.6)\n",
      "Requirement already satisfied: databricks-cli>=0.8.7 in /usr/local/lib/python3.8/site-packages (from mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (0.17.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/site-packages (from mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (1.2.5)\n",
      "Requirement already satisfied: alembic in /usr/local/lib/python3.8/site-packages (from mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (1.8.0)\n",
      "Requirement already satisfied: Flask in /usr/local/lib/python3.8/site-packages (from mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (2.1.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/site-packages (from mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (5.4.1)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.8/site-packages (from mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (2021.3)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/site-packages (from mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (2.0.0)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.8/site-packages (from mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (0.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/site-packages (from mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (1.7.0)\n",
      "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.8/site-packages (from mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (0.4.2)\n",
      "Requirement already satisfied: gunicorn in /usr/local/lib/python3.8/site-packages (from mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (20.1.0)\n",
      "Requirement already satisfied: prometheus-flask-exporter in /usr/local/lib/python3.8/site-packages (from mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (0.20.2)\n",
      "Requirement already satisfied: gitpython>=2.1.0 in /usr/local/lib/python3.8/site-packages (from mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (3.1.27)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/site-packages (from mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (21.3)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/site-packages (from mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (8.1.3)\n",
      "Requirement already satisfied: querystring-parser in /usr/local/lib/python3.8/site-packages (from mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (1.2.4)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,>=3.7.0 in /usr/local/lib/python3.8/site-packages (from mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (4.8.2)\n",
      "Requirement already satisfied: docker>=4.0.0 in /usr/local/lib/python3.8/site-packages (from mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (5.0.3)\n",
      "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.8/site-packages (from mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (1.4.37)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.8/site-packages (from boto3->-r utils/keras_rewrite/requirements.txt (line 5)) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.8/site-packages (from boto3->-r utils/keras_rewrite/requirements.txt (line 5)) (0.5.0)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.22 in /usr/local/lib/python3.8/site-packages (from boto3->-r utils/keras_rewrite/requirements.txt (line 5)) (1.23.22)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/site-packages (from botocore<1.24.0,>=1.23.22->boto3->-r utils/keras_rewrite/requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.8/site-packages (from botocore<1.24.0,>=1.23.22->boto3->-r utils/keras_rewrite/requirements.txt (line 5)) (1.25.11)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.8/site-packages (from databricks-cli>=0.8.7->mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (0.8.9)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in /usr/local/lib/python3.8/site-packages (from databricks-cli>=0.8.7->mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (2.4.0)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.8/site-packages (from databricks-cli>=0.8.7->mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (3.1.1)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.8/site-packages (from docker>=4.0.0->mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (1.3.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.8/site-packages (from gitpython>=2.1.0->mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (4.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard->-r utils/keras_rewrite/requirements.txt (line 2)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard->-r utils/keras_rewrite/requirements.txt (line 2)) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard->-r utils/keras_rewrite/requirements.txt (line 2)) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r utils/keras_rewrite/requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/site-packages (from importlib-metadata!=4.7.0,>=3.7.0->mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (3.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard->-r utils/keras_rewrite/requirements.txt (line 2)) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard->-r utils/keras_rewrite/requirements.txt (line 2)) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard->-r utils/keras_rewrite/requirements.txt (line 2)) (2.10)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/site-packages (from alembic->mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (5.4.0)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.8/site-packages (from alembic->mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/site-packages (from sqlalchemy->mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (1.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.8/site-packages (from Flask->mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (2.1.2)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.8/site-packages (from Flask->mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (3.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/site-packages (from packaging->mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (3.0.6)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/site-packages (from prometheus-flask-exporter->mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (0.12.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/site-packages (from Jinja2>=3.0->Flask->mlflow->-r utils/keras_rewrite/requirements.txt (line 4)) (2.0.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->-r utils/keras_rewrite/requirements.txt (line 2)) (0.4.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r utils/keras_rewrite/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ludfxbNIaegy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training these words: yes,no\n",
      "Training steps in each stage: 12000,3000\n",
      "Learning rate in each stage: 0.001,0.0001\n",
      "Total number of training steps: 15000\n"
     ]
    }
   ],
   "source": [
    "# A comma-delimited list of the words you want to train for.\n",
    "# The options are: yes,no,up,down,left,right,on,off,stop,go\n",
    "# All the other words will be used to train an \"unknown\" label and silent\n",
    "# audio data with no spoken words will be used to train a \"silence\" label.\n",
    "WANTED_WORDS = \"yes,no\"\n",
    "\n",
    "# The number of steps and learning rates can be specified as comma-separated\n",
    "# lists to define the rate at each stage. For example,\n",
    "# TRAINING_STEPS=12000,3000 and LEARNING_RATE=0.001,0.0001\n",
    "# will run 12,000 training loops in total, with a rate of 0.001 for the first\n",
    "# 8,000, and 0.0001 for the final 3,000.\n",
    "TRAINING_STEPS = \"12000,3000\"\n",
    "LEARNING_RATE = \"0.001,0.0001\"\n",
    "\n",
    "# Calculate the total number of steps, which is used to identify the checkpoint\n",
    "# file name.\n",
    "TOTAL_STEPS = str(sum(map(lambda string: int(string), TRAINING_STEPS.split(\",\"))))\n",
    "\n",
    "# Print the configuration to confirm it\n",
    "print(\"Training these words: %s\" % WANTED_WORDS)\n",
    "print(\"Training steps in each stage: %s\" % TRAINING_STEPS)\n",
    "print(\"Learning rate in each stage: %s\" % LEARNING_RATE)\n",
    "print(\"Total number of training steps: %s\" % TOTAL_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCgeOpvY9pAi"
   },
   "source": [
    "**DO NOT MODIFY** the following constants as they include filepaths used in this notebook and data that is shared during training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Nd1iM1o2ymvA"
   },
   "outputs": [],
   "source": [
    "# Calculate the percentage of 'silence' and 'unknown' training samples required\n",
    "# to ensure that we have equal number of samples for each label.\n",
    "number_of_labels = WANTED_WORDS.count(',') + 1\n",
    "number_of_total_labels = number_of_labels + 2 # for 'silence' and 'unknown' label\n",
    "equal_percentage_of_training_samples = int(100.0/(number_of_total_labels))\n",
    "SILENT_PERCENTAGE = equal_percentage_of_training_samples\n",
    "UNKNOWN_PERCENTAGE = equal_percentage_of_training_samples\n",
    "\n",
    "# Constants which are shared during training and inference\n",
    "PREPROCESS = 'micro'\n",
    "WINDOW_STRIDE = 20\n",
    "MODEL_ARCHITECTURE = 'tiny_conv' # Other options include: single_fc, conv,\n",
    "                      # low_latency_conv, low_latency_svdf, tiny_embedding_conv\n",
    "\n",
    "# Constants used during training only\n",
    "VERBOSITY = 1\n",
    "EVAL_STEP_INTERVAL = '1000'\n",
    "SAVE_STEP_INTERVAL = '1000'\n",
    "\n",
    "# Constants for training directories and filepaths\n",
    "DATASET_DIR =  'dataset/'\n",
    "LOGS_DIR = 'logs/'\n",
    "TRAIN_DIR = 'train/' # for training checkpoints and other files.\n",
    "NO_MLFLOW= True\n",
    "\n",
    "# Constants for inference directories and filepaths\n",
    "import os\n",
    "MODELS_DIR = 'models'\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "  os.mkdir(MODELS_DIR)\n",
    "\n",
    "MODEL_TF = MODELS_DIR + '/model_2.pb'\n",
    "MODEL_TFLITE = MODELS_DIR + '/tflite/model_final.tflite'\n",
    "FLOAT_MODEL_TFLITE = MODELS_DIR + '/tflite/float_model_final.tflite'\n",
    "MODEL_TFLITE_MICRO = MODELS_DIR + '/tflite/model_final.cc'\n",
    "SAVED_MODEL = MODELS_DIR + '/saved_model'\n",
    "\n",
    "QUANT_INPUT_MIN = 0.0\n",
    "QUANT_INPUT_MAX = 26.0\n",
    "QUANT_INPUT_RANGE = QUANT_INPUT_MAX - QUANT_INPUT_MIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rLYpvtg9P4o"
   },
   "source": [
    "## Setup Environment\n",
    "\n",
    "Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ed_XpUrU5DvY"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9Ty5mR58E4i"
   },
   "source": [
    "**DELETE** any old data from previous runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "APGx0fEh7hFF"
   },
   "outputs": [],
   "source": [
    "# !rm -rf {LOGS_DIR} {TRAIN_DIR} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfEUlfFBizio"
   },
   "source": [
    "Clone the TensorFlow Github Repository, which contains the relevant code required to run this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nS9swHLSi7Bi"
   },
   "source": [
    "Load TensorBoard to visualize the accuracy and loss as training proceeds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1J96Ron-O4R"
   },
   "source": [
    "## Training\n",
    "\n",
    "The following script downloads the dataset and begin training.\n",
    "\n",
    "Uncomment to start training. leave it commented if you would like to use pretarined model.\n",
    "\n",
    "for training you need to change the name of the laod-weights argument by the latest model created by the training script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "id": "VJsEZx6lynbY",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-17 21:40:38.677969: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "2022-05-17 21:40:38.678097: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "2022-05-17 21:40:38.708032: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "File already exists at dataset/speech_commands_v0.02.tar.gz\n",
      "Gathering .wav files from dataset/ : 100%|█| 105835/105835 [00:00<00:00, 118413.\n",
      "Reading data index...\n",
      "Validation partition: 1339 entries\n",
      "Testing partition: 1374 entries\n",
      "Training partition: 10598 entries\n",
      "2022-05-17 21:40:58.241344: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-17 21:40:58.244001: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Generating validation partition: 100%|█████| 1339/1339 [00:06<00:00, 205.65it/s]\n",
      "Generating testing partition: 100%|████████| 1374/1374 [00:06<00:00, 212.27it/s]\n",
      "Generating training partition: 100%|█████| 10598/10598 [00:53<00:00, 199.81it/s]\n",
      "2022-05-17 21:42:05.223468: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "(1960,)\n",
      "\n",
      "Model creation complete.\n",
      "Model: \"tiny_conv\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (100, 49, 40, 1)          0         \n",
      "_________________________________________________________________\n",
      "convolutional (Conv2D)       (100, 25, 20, 8)          648       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (100, 25, 20, 8)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (100, 4000)               0         \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      (100, 4)                  16004     \n",
      "=================================================================\n",
      "Total params: 16,652\n",
      "Trainable params: 16,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2022/05/17 21:42:05 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'c9b3a97127e84360b3ed5a5bf30cca37', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n",
      "Epoch 1/10\n",
      "Extension horovod.torch has not been built: /usr/local/lib/python3.8/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-38-x86_64-linux-gnu.so not found\n",
      "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "Warning! MPI libs are missing, but python applications are still avaiable.\n",
      "[2022-05-17 21:42:05.936 tensorflow-2-6-cpu-py-ml-t3-medium-9169b2e75617c45c79c40579f6a8:734 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-05-17 21:42:06.003 tensorflow-2-6-cpu-py-ml-t3-medium-9169b2e75617c45c79c40579f6a8:734 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "WARNING:tensorflow:Model was constructed with shape (100, 1960) for input KerasTensor(type_spec=TensorSpec(shape=(100, 1960), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (100, 49, 40, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (100, 1960) for input KerasTensor(type_spec=TensorSpec(shape=(100, 1960), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (100, 49, 40, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (100, 1960) for input KerasTensor(type_spec=TensorSpec(shape=(100, 1960), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (100, 49, 40, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (100, 1960) for input KerasTensor(type_spec=TensorSpec(shape=(100, 1960), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (100, 49, 40, 1).\n",
      "15000/15000 [==============================] - ETA: 0s - loss: 0.4953 - sparse_categorical_accuracy: 0.8154- ETA: 0s - loss: 0.4957 - sparse_categorical_accWARNING:tensorflow:Model was constructed with shape (100, 1960) for input KerasTensor(type_spec=TensorSpec(shape=(100, 1960), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (100, 49, 40, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (100, 1960) for input KerasTensor(type_spec=TensorSpec(shape=(100, 1960), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (100, 49, 40, 1).\n",
      "15000/15000 [==============================] - 203s 13ms/step - loss: 0.4953 - sparse_categorical_accuracy: 0.8154 - val_loss: 0.3579 - val_sparse_categorical_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: sparse_categorical_accuracy improved from -inf to 0.81544, saving model to train/run_local/ckpt/weights-01-0.8154.h5\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 202s 13ms/step - loss: 0.3775 - sparse_categorical_accuracy: 0.8633 - val_loss: 0.3494 - val_sparse_categorical_accuracy: 0.8715uracy: - ETA: 7s - loss: 0.3776 - sparse_categorical_accuracy: 0.863 - ETA: 7s - loss: 0.3776 - sparse_categorical_accuracy: 0.863 - E - ETA: 4s - loss: 0.3775 - sparse_categorical_accuracy: 0.86 - ETA: 3s - loss: 0 - ETA: 1s - loss: 0.3775 - sparse\n",
      "\n",
      "Epoch 00002: sparse_categorical_accuracy improved from 0.81544 to 0.86332, saving model to train/run_local/ckpt/weights-02-0.8633.h5\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 200s 13ms/step - loss: 0.3674 - sparse_categorical_accuracy: 0.8666 - val_loss: 0.3413 - val_sparse_categorical_accuracy: 0.8731- ETA: 0s - loss: 0.3674 - sparse_categorical_accuracy: 0.86\n",
      "\n",
      "Epoch 00003: sparse_categorical_accuracy improved from 0.86332 to 0.86656, saving model to train/run_local/ckpt/weights-03-0.8666.h5\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 199s 13ms/step - loss: 0.3585 - sparse_categorical_accuracy: 0.8701 - val_loss: 0.3352 - val_sparse_categorical_accuracy: 0.8731\n",
      "\n",
      "Epoch 00004: sparse_categorical_accuracy improved from 0.86656 to 0.87012, saving model to train/run_local/ckpt/weights-04-0.8701.h5\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 204s 14ms/step - loss: 0.3500 - sparse_categorical_accuracy: 0.8732 - val_loss: 0.3293 - val_sparse_categorical_accuracy: 0.8738TA: 3:20  - ETA: 3:15 - - ETA: 3:11 - loss: 0.3544 - sparse_c - - ETA: 3: - ETA: 3:04 - loss: 0.3532 - sparse_categorical_ - ETA: 2:59 - loss: 0.3534 - sparse_categorical_accuracy: 0.8 -  - ETA: 2:14 - loss: 0.3526 - sparse_categorical_accuracy: 0.872 - ETA: 2:14 - loss: 0.3526 - sparse_ca - ETA: 2:13 - loss: 0.3525 - sparse_categorical_accurac - ETA: 2:12 - loss: 0.3526 - sparse_categor - ETA: 2:11 - loss: 0.3525 - sparse_categorical_accuracy: 0.872 - ETA: 2:11 - loss: 0.3526 - sparse_categorical - ETA: 2:10 - loss: 0.3526 - sparse_categ - ETA: 2:09 - loss: - ET - ETA: 2:03 - loss: 0.3524 - - ETA: 2: - ETA: 1:58 - loss: 0.3523 - sparse_categor - ETA: 1:49 - l - ETA: 1:47 - loss: 0.3523 - sparse_c - ETA: 1:31 - loss: 0.3519 - sparse_categorical_accuracy: 0.87 - ETA: 1:31 - loss: 0.3519 - sparse_categorical_accuracy: 0.872 - ETA: 1: - ETA: 1:28 - loss: 0.3518 - s - ETA: 1:26 - loss: 0.3518 - sparse_c - ETA: 1:25 - loss: 0.3517 - sparse_categorical_accuracy: 0.87 - ETA: 1:24 - loss: 0.3518 - sparse_categorical_ - ETA: 1:24 - loss: 0.351 - ETA: 1:19 - loss: 0.3516 - sparse_categorical_accuracy - ETA: 1:18 - loss: 0.3516 - spars - ETA: 1:16 - loss: 0.3515 -  - ETA: 1:14 - loss: 0.3515 - ETA: 1:09 - loss: 0.3514 - sparse_categoric - ETA: 1:08 - loss: 0.3 - ETA: 1:06 - loss: 0.3513 - sparse_categorical_accuracy: 0.87 - ETA: 1:06 - loss: 0.3513 - sparse_categorical_accurac - ETA: 1:05 - loss: 0.3513 - sparse_categorical - ETA: 1:04 - lo - ETA: 17s - loss: 0.3503 - sparse_categorical_accuracy: 0.87 - ETA: 17s - loss: 0.3503 - sparse_categorica - ETA: 15s - loss: - ETA: 3s - loss: 0.3501 - sparse_categorical_accu - ETA: 2s - loss: 0.3500 - sparse_categorical_a - ETA: 2s - loss: 0.3500 - sparse_categorical_accu - ETA: 1s - loss: 0.3500 - sparse_ca\n",
      "\n",
      "Epoch 00005: sparse_categorical_accuracy improved from 0.87012 to 0.87317, saving model to train/run_local/ckpt/weights-05-0.8732.h5\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 213s 14ms/step - loss: 0.3433 - sparse_categorical_accuracy: 0.8752 - val_loss: 0.3232 - val_sparse_categorical_accuracy: 0.8762A: 3:22 - loss: 0.3549 - sparse_categorical_accuracy: 0.8 - ETA: 3:22 - loss: 0.3515 - sparse_categorical - ETA: 3:23 - loss: 0.3496 - sparse_categorical_accura - ETA: 3:23 - loss: 0.3476 - sparse_categorical_acc - ETA: 3:23 - loss: 0.3492 - sparse_catego - ETA: 3:21 - loss: 0.3478 - sparse_categorical - ETA: 3:20 - loss: 0.3464 - spars - ETA: 3:25 - loss: 0.3460 - sparse_categori - ETA: 3:23 - loss: 0.3462 - sparse_categorical_accuracy: 0.87 - ETA: 3:23 - loss: 0. - ETA: 3:1 - ETA: 3:10 - loss: 0.3457 - sparse_categorical_accuracy: 0.87 - ETA: 3:10 - loss: 0.3457  - ETA: 3: - ETA: 3:00 - loss: 0.3462 - sparse_categori - ETA: 2:58 - loss: 0.3462 - sparse - ETA: 2:57 - - ETA: 2:53 - loss: 0.3462 - sparse_cate - ETA: 2:52 - loss: 0.3463 - sparse_categorical_ac - ETA: 2:51 - loss: 0.3461 - sparse_categor - ETA: 2:50 - loss: 0.3463 - sparse_cate - ETA: 2:48 - los - ETA: 2:45 - loss: 0.346 - ETA: 2:43 - loss: 0.3459 - spars - ETA: 2:41 - loss: 0.3458 - sparse_categorical_accuracy: 0.8 - ETA: 2:41 - loss: 0.3458 - sparse_categorical_accuracy: 0.87 - ETA: 2:41 - loss: 0.3 - ETA: 2:38 - loss: 0.3459 - sparse_c - ETA: 2:37 - loss: 0.3460 - sparse_categorical_accuracy: 0.874 - ETA: 2:37 - loss: 0.3459  - ETA: 2:34 - lo - ETA: 2:31 - loss: 0.3459 - sparse_categorical - ETA: 2:30 - loss: 0.3460 - sparse_categorical_acc - ETA: 2:30 - loss: 0.3461 - sparse_cate - ETA: 2:28 - loss: 0.3461 - sparse_categor - ETA: 2:27 - loss: 0.3461 - sparse_categorical_accuracy: 0.874 - ETA: 2:27 - loss: 0.3461 - sparse_categorical_accuracy: 0.874 - ETA: 2:27 - loss: 0.3461 - sparse_categorical_accuracy: 0.874 - ETA: 2:27 - loss: 0.3461 - sparse_categorical_accuracy: 0.87 - ETA: 2:27 - loss: 0.3461 - sparse_categoric - ETA: 2:26 - loss: 0.3461 - sparse_categorical_accuracy: 0. - ETA: 2:25 - loss: 0.3461 - sparse_categorica - ETA: 2:24 - loss: 0.3461 - spars -  - ETA: 2:21 - loss: 0.3461 - sparse_categorical_accuracy: 0.87 - ETA: 2:21 - loss: 0.3461 - sparse_categori - ETA: 2:20 - loss: 0.3460 - sparse_categorical_accuracy: 0.874 - ETA: 2:20 - loss: 0.3461 - sparse_categorical_accuracy: 0.874 - ETA: 2:20 - loss: 0.34 - ETA: 2:17 - loss: 0.3460 - sparse_catego - ETA: 2:16 - loss: 0.3459 - spa - ETA: 2:14 - loss: 0.3458 - sparse_ca - ETA: 2:12 - loss: 0.3457 - sparse_cate - ETA: 2:11 - loss: 0.3457 - sparse_categorical_accur - ETA: 2:10 - loss: 0.3456 - sparse_categorical_accuracy: 0.87 - ETA: 2:10 - loss: 0.3457 - sparse_categorical_accu - ETA: 2:10 - loss: 0.3457 - sparse_categorical_ - ETA: 2:09 - loss: 0.3457 - sparse_categorical_accuracy: 0.874 - ETA: 2:09 - loss: 0.3456 - sparse_categorical_ac - ETA: 2:08 - loss: 0.3456 - sparse_categorical_accu - ETA: 2:07 - loss: 0.3456 - sparse_categorical_acc - ETA: 2:06 - loss: 0.3457 - sparse - ETA: 2:05 - loss: 0.3 - ETA: 2:02 - loss: 0.3455 - sparse_categorical_accuracy: 0.87 - ETA: 2:02 - loss: 0.3456 - sparse_categorical_ac - ETA: 2:01 - loss: 0.3456 - sparse_categorical_accur - ETA: 2:00 - loss: 0.3456 - sparse_catego - ETA: 1:59 - loss: 0.3455 - s - ETA: 1:57 - loss: 0.3454 - sparse_categorical_accuracy: 0.874 - ETA: 1:57 - loss: 0.3454 - sparse_categorical_accur - ETA: 1:56 - loss: 0.3454 - sparse_categorical_accuracy: 0.87 - ETA: 1:56 - loss: 0.3454 - sparse_categorical_ac - ETA: 1:55 - loss: 0.3454 - sparse_cate - ETA: 1:5 - ETA: 1:51 - loss: 0.3453 - sparse_categorical_accuracy: 0.87 - ETA: 1:50 - loss: 0.3453 - sparse_categorical_acc - ETA: 1:50 - loss: 0.3453 - sparse_categ - ETA: 1:48 - loss: 0.3453 - sparse_categorical_a - ETA: 1:47 - loss: 0.3453 - sparse_categorical_ - ETA: 1:47 - loss: 0.3452 - sparse_ca - ETA: 1:45 -  - ETA: 1:42 - loss: - ETA:  - ETA: 1:36 - loss: 0.3449 - sparse_categorical_accuracy: 0.874 - ETA: 1:36 - loss: 0.3449 - sparse_categorical_acc - ETA: 1:35 - loss: 0.3449 - sparse_categorical_accuracy: 0.874 - ETA: 1:35 - loss:  - ETA: 1:33 - loss: 0.3450 - sparse_categoric - ETA: 1:31 - loss: 0.3450 - sparse_categor -  - ETA: 1:27 - loss: 0.3449 - sparse_categorical_accura - ETA: 1:26 - loss: 0.3449 - sparse_catego - ETA: 1:25 - loss: 0.3449 - sparse_categorical_accuracy: 0.8 - ETA: 1:22 - loss: 0 - ETA: 1:19 - loss: 0.3449 - sparse_categorical_acc - ETA: 1:18 - loss: 0.3448 - sparse_c - ETA: 1:17 - loss: 0.3448 - sparse_categorical_accuracy:  - ETA: 1:17 - loss: 0.3448 - sparse_categor - ETA: 1:15 - loss: 0.3447 - sparse_categorical_accuracy: 0.874 - ETA: 1:15 - loss: 0.3 - ETA: 1:13 - loss: 0.3446 - sparse_categorical_accurac - ETA: 1:12 - loss: 0.3446 - sparse_categorica - ETA: 1:11 - loss: 0.3446 - sp - ETA: 1:10 - loss: 0.3445 - sparse_cat - ETA: 1:08 - loss: 0.3445 - sparse_categorical_accuracy: 0.8 - ETA: 1:08 - loss: 0.3445 - sparse_categorica - ETA: 1:07 - loss: 0.344 - ETA: 1:05 - loss: 0.3445 - sparse_c - ETA: 1:03 - loss: 0.3445 - sparse_categorical_accuracy: 0. - ETA: 1:03 - loss: 0.3445 - sparse_categorical_accur - ETA: 1:02 - loss: 0.3444 - sparse_categorica - ETA: 1:01 - loss: 0.3444 - sparse_categorical_accuracy - ETA: 1:01 - loss: 0.3443 - sparse_categor - ETA: 1:00 - loss: 0.3444  - ETA: 58s - loss: 0.34 - ETA: 57s - loss: 0.3443 - sparse_catego - ETA: 57s - loss:  - ETA: 55s - loss: 0.3443 - sparse_catego - - ETA: 53s - loss: 0.3442 - sparse_categorical_accuracy: 0. - ETA: 53 - ETA: 51s - loss: 0.3442 - s - ETA: 50s - loss: 0.3442 - sparse_categorical_accuracy: 0. - ETA: 50s - loss: 0.3442 - sparse_categorical_accuracy - ETA: 41s - loss: 0.34 - ETA: 39s - loss: 0.3438 - sparse_catego - ETA: 39s - loss: 0.3439 - sparse_ - ETA: 38s - loss: 0.3438 - sparse_catego - ETA: 37s - loss: 0.3439 - sparse_categorical_accuracy: 0. - ETA: 37s - loss: 0.3439 - sparse_categorical_accuracy: 0. - ETA: 37s - loss: 0.3438 - s - ETA: 36s - loss: 0.3438 - spars - ETA: 35s - loss: 0.3438 - sparse_categorical_accuracy: 0.87 - ETA: 35s - loss:  - ETA: 32s - loss: 0.34 - ETA: 29s - loss: 0.3437 - sparse_cate - ETA: 29s - loss: 0.3437 - sparse_categorical_accuracy: 0. - ETA: 29s - loss: 0. - ETA: 27s - loss: 0.3437 - sparse_categorical_accuracy: 0.87 - ETA: 27s - loss: 0.3437 - sparse_ca - ETA - ETA: 25s - loss: 0.3437 - sparse_categori - ETA: 24s - loss: 0.3437 - spars - ETA: 24s - loss: 0.3437 - spars - ETA: 23s - loss - ETA: 21s - loss: 0.3437 - sparse_catego - ETA: 21s - loss: 0. - ETA: 16s - loss: 0.3436 - spars - ETA: 15s - loss: 0.3437 - sparse_categorical_accuracy: 0.87 - ETA: 15s - loss: 0.3436 - sparse_categori - ETA: 15s - loss: 0. - ETA: 10s - loss: 0.3436 - sparse_categorical_ - ETA: 9s - loss: 0.3435 - sparse_categorical_ac - ETA: 8s - loss: 0.3435 - sparse_catego - ETA: 7s - loss: 0.3435 - - ETA: 5s - loss: 0.3435 - sparse_categorical_a - ETA: 4s - loss: 0.3434 - sparse_categorical_accuracy: 0.87 - ETA: 4s - loss: 0.3434 - sparse_categorical_accu - ETA: 3s - loss: 0.3434 - sparse_categorical_accuracy: 0.8 - ETA: 3s - loss: 0.3434 - sparse_categor - ETA: 2s - loss: 0.3434 - sparse_categorical_accuracy: 0.8 - ETA: 1s - loss: 0.3434 - sparse_categorical_accuracy:  - ETA: 1s - loss: 0.3433 - sparse_categorical_accur - ETA: 0s - loss: 0.3433 - sparse_categorical_a\n",
      "\n",
      "Epoch 00006: sparse_categorical_accuracy improved from 0.87317 to 0.87523, saving model to train/run_local/ckpt/weights-06-0.8752.h5\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 213s 14ms/step - loss: 0.3359 - sparse_categorical_accuracy: 0.8784 - val_loss: 0.3177 - val_sparse_categorical_accuracy: 0.880028 - loss: 0.3376 - sparse_categori - ETA: 3:28 - loss: 0.3375 - sparse_categori - ETA: 3:27 - loss: 0.3383 - sparse_categorical_acc - ETA: 3:26 - loss: 0.3390 - sparse_categorical_accuracy - ETA: 3:28 - loss: 0.3400 - sparse_categorical_accuracy: 0. - ETA: 3:28 - loss: 0.3396 - sparse_ca - ETA: 3:25 - loss: 0.3400 - sparse_categorical_a - ETA: 3:24 - loss: 0.3396 - sparse_categorical_accur - ETA: 3:23 - loss: 0.3392 - sparse_categorical_ac - ETA: 3:23 - loss: - ETA: 3:20 - loss: 0.3393 - sparse_categorical_a - ETA: 3:19 - loss: 0.3395 - sparse_categorical_accuracy: 0. - ETA: 3:18 - loss: 0.3389 - sparse_categorical_accuracy: 0.87 - ETA: 3:18 - loss: 0.3 - ETA: 3:16 - loss: 0.3396 - sparse_categorica - ETA: 3:15 - loss: 0.3395 - sparse_cat - ETA: 3:14 - loss: 0.3395 - sparse_categorical_accurac - ETA: 3:13 - loss: 0.3392 - sparse_categorical_accuracy: 0.87 - ETA: 3:13 - loss: 0.3390 - sparse_categorical_accura - ETA: 3:13 - loss: 0.3389 - sparse_categorical_accuracy: 0.87 - ETA: 3:12 - loss: 0.3392 - sparse_categorical_accuracy: 0.87 - ETA: 3:12 - loss: 0.3389 - sparse_categorical_accura - ETA: 3:12 - loss: 0.3389 - sparse_categorical_accuracy: 0.8 - ETA: 3:11 - loss: 0.3393 - sparse_categorical_accurac - ETA: 3:11 - loss: 0.3393 - sparse_categorical_accuracy: 0. - ETA: 3:11 - loss: 0.3391 - sparse_categorical_accur - ETA: 3:10 - loss: 0.3390 - sparse_categoric - ETA: 3:09 - loss: 0.3392 - sparse_categorical_accu - ETA: 3:09 - loss: 0.3392 - sparse_categorical_accuracy: 0. - ETA: 3:08 - loss: 0.3 - ETA: 3:06 - loss: 0.3388 - sparse_categorical_accur - ETA: 3:05 - loss: 0.3388 - sparse_categorical_acc - ETA: 3:05 - loss: 0.3389 - sparse_categorical_ - ETA: 3:04 - loss: 0.3388 - sparse_categorical_accuracy: 0.8 - ETA: 3:03 - loss: 0.3387 - sparse_categorical_a - ETA: 3:02 - loss: 0.3388 - sparse_categorical_accuracy: 0.878 - ETA: 3:02 - loss: 0.3388 - sparse_categorical_ac - ETA: 3:01 - loss: 0.3387 - sparse_categorical_accuracy: 0 - ETA: 3:01 - loss: 0.3386 - sparse_categorical_accuracy: 0.87 - ETA: 3:01 - loss: 0.3387 - sparse_catego - ETA: 2:59 - loss: 0.3387 - sparse_categorical_accuracy: 0.877 - ETA: 2:59 - loss: 0.3387 - sparse_categorical_ - ETA: 2:58 - loss: 0.3387 - sparse_categorical_accuracy: 0.877 - ETA: 2:58 - loss: 0.3387 - sparse_catego - ETA: 2:57 - loss: 0.3387 - sparse_categorical_acc - ETA: 2:57 - loss: 0.3385 - sparse_ca - ETA: 2:57 - loss: 0.3384 - sparse_categor - ETA: 2:56 - loss: 0.3384 - spa - ETA: 2:54 - loss: 0.3383 - sparse_categorical_accu - ETA: 2:54 - loss: 0.3383 - sparse_categorical_a - ETA: 2:53 - loss: 0.3382 - sparse_categorical_accuracy: 0.87 - ETA: 2:53 - loss: 0.3382 - sparse_categorical_ac - ETA: 2:52 - loss: 0.3382 - sparse_categorical_accuracy: 0.8 - ETA: 2:52 - loss: 0.3382 - sparse_categorical_accura - ETA: 2:51 - loss: 0.3382 - sparse_categorical_ac - ETA: 2:50 - loss: 0.3382 - spars - ETA: 2:49 - loss: 0.3382 - sparse_categorical_acc - ETA: 2:48 - loss: 0.3383 - sparse_categorical_accu - ETA: 2:47 - loss: 0.3382 - sparse_categorical_accuracy: 0.87 - ETA: 2:47 - loss: 0.3382 - sparse_categorical_accuracy: 0 - ETA: 2:47 - loss: 0.3381 - sparse_categorical_accuracy: 0.8 - ETA: 2:47 - loss: 0.3380 - sparse_categorical_accu - ETA: 2:46 - loss: 0.3381 - - ETA: 2:44 - loss: 0.3380 - sparse_categorical_accu - ETA: 2:43 - loss: 0.3380 - sparse_categorical_accur - ETA: 2:42 - loss: 0.3379 - sparse_categorical_accuracy: 0.87 - ETA: 2:42 - loss: 0.3380 - sparse_categorical_accu - ETA: 2:41 - loss: 0.3379 - sparse_categorica - ETA: 2:40 - loss: 0.3378 - sparse_categorical_accur - ETA: 2:40 - loss: 0.3378 - sparse_categorical_accuracy: 0.8 - ETA: 2:40 - loss: 0.3379 - sparse_categorical_accu - ETA: 2:39 - loss: 0.3378 - sparse_categorical_accuracy: 0.87 - ETA: 2:39 - loss: 0.3378 - sparse_c - ETA: 2:37 - loss: 0.3378 - sparse_categorical_accuracy: 0.87 - ETA: 2:37 - loss: 0.3378 - sparse_categorical_accuracy: 0.87 - ETA: 2:37 - loss: 0.3379 - sparse_categorical_ - ETA: 2:36 - loss: 0.3379 - sparse_categorical - ETA: 2:35 - loss: 0.3379 - sparse_categorical_accuracy: 0.87 - ETA: 2:35 - loss: 0.3379 - sparse_categorical_acc - ETA: 2:34 - loss: 0.3378 - sparse_categorical_accuracy: 0. - ETA: 2:34 - loss: 0.3380 - sparse_categorical_accuracy: 0.87 - ETA: 2:34 - loss: 0.3379 - sparse - ETA: 2:32 - loss: - ETA: 2:29 - loss: 0.3379 - spa - ETA: 2:28 - loss: 0.3378 - sparse_categorical_accuracy: 0.87 - ETA: 2:27 - loss: 0.3377 - sparse_catego - ETA: 2:26 - loss: 0.3377 - sparse_categorical_ - ETA: 2:25 - loss: 0.3377 - sparse_categorical_a - ETA: 2:24 - loss: 0.3376 - sparse_categori - ETA: 2:23 - loss: 0.3377 - sparse_categorical_accuracy: 0.87 - ETA: 2:23 - loss: 0.3376 - sparse_categorical_accuracy: 0.87 - ETA: 2:23 - loss: 0.3376 - sparse_categorical_accura - ETA: 2:22 - loss: 0.3376 - sparse_c - ETA: 2:21 - loss: 0.3377 - sparse_categorical_accuracy: 0.87 - ETA: 2:21 - loss: 0.3376 - sparse_categorical_accura - ETA: 2:20 - loss: 0.3376 - sparse_categorical_accuracy - ETA: 2:20 - loss: 0.3376 - sparse - ETA: 2:18 - loss: 0.3375 - sparse_categorical_accuracy: 0.87 - ETA: 2:18 - loss: 0.3375 - sparse_categorical_accuracy: 0.878 - ETA: 2:18 - loss: 0.3375 - sparse_categorical_accuracy: 0.878 - ETA: 2:18 - loss: 0.3375 - sparse_categori - ETA: 2:16 - loss: 0.3376 - sparse_categ - ETA: 2:15 - loss: 0.3375 - sparse_categorical_accuracy: 0.8 - ETA: 2:15 - loss: 0.3376 - sparse_categorical_accur - ETA: 2:14 - loss: 0.3375 - sparse_categorical_accuracy: 0. - ETA: 2:14 - loss: 0.3375 - ETA: 2:12 - loss: 0.3374 - sparse_categorical_accuracy: - ETA: 2:11 - loss: 0.3373 - sparse_categorical_ - ETA: 2:10 - loss: 0.3374 - sparse_categorical_accu - ETA: 2:10 - loss: 0.3374 - sparse_categorical_accuracy:  - ETA: 2:09 - loss: 0.3374 - spa - ETA: 2:07 - loss: 0.3373 - sparse_categorical_ - ETA: 2:06 - loss: 0.3374 - sparse_categorical_a - ETA: 2:06 - loss: 0.3374 - sparse_c - ETA: 2:04 - loss: 0.3374 - sparse_categorical_accuracy: 0.87 - ETA: 2:04 - loss: 0.3374 - sparse_categori - ETA: 2:03 - loss: 0.3374 - sparse_categorical_accu - ETA: 2:02 - loss: 0.3374 - sparse_categorical_accuracy: 0.8 - ETA: 2:02 - loss: 0.3374 - sparse_categorical_accuracy: 0.87 - ETA: 2:02 - loss: 0.3374 - sparse_categ - ETA: 2:01 - loss: 0.3375 - sparse_categoric - ETA: 1:59 - loss: 0.3374 - sparse_ - ETA: 1:58 - loss: 0.3373 - sparse_catego - ETA: 1:57 - loss: 0.3373 - sparse_cate - ETA: 1:56 - loss: 0.3373 - sparse_categorical_accuracy: 0.87 - ETA: 1:55 - loss: 0.3373 - sparse_categorical_acc - ETA: 1:55 - loss: 0.3374 - sparse_categorica - ETA: 1:54 - loss: 0.3373 - sparse_categorical_accu - ETA: 1:53 - loss: 0.3374 - sparse_ca - ETA: 1:52 - loss: 0.3373 - sparse_categorical_a - ETA: 1:51 - lo - ETA: 1:48 - loss: 0.3373 - sparse_categorica - ETA: 1:47 - loss: 0.3373 - sparse_categorical - ETA: 1:46 - loss: 0.3372 - sparse_categorical_accur - ETA: 1:45 - loss: 0.3372 - sparse_categorical_accu - ETA: 1:44 - loss: 0.3373 - sparse_categorical_accuracy: 0.877 - ETA: 1:44 - los - ETA: 1:41 - loss: 0.3373 - sparse_categorical_accuracy: 0. - ETA: 1:41 - loss: 0.3372 - sparse_categorical_accuracy: 0.87 - ETA: 1:41 - loss: 0.3372 - sparse_ca - ETA: 1:40 - loss: 0.3371 - sparse_categorical_ac - ETA: 1:39 - loss: 0.3372 - sparse_categorical_accuracy: - ETA: 1:38 - loss: 0.3372 - sparse_categorica - ETA: 1:37 - loss: 0.3372 - s - ETA: 1:35 - loss: 0.3372 - sparse_categorical_ac - ETA: 1:35 - loss: 0.3371 - sparse_categorical_accuracy: 0 - ETA: 1:34 - loss: 0.3371 - sparse_categorical_accuracy: 0.878 - ETA: 1:34 - loss: 0.3372 - sparse_categorical_a - ETA: 1:33 - loss: 0.3371 - sparse_categor - ETA: 1:32 - loss: 0.3371 - sparse_categori - ETA: 1:31 - loss: 0.3370 - sparse_categorical_accuracy: 0.8 - ETA: 1:31 - loss: 0.3371 - sparse_categorical_accuracy: 0. - ETA: 1:31 - loss: 0.3371 - sparse - ETA: 1:29 - loss: 0.3370 - sparse_categorical_accuracy: 0. - ETA: 1:29 - loss: 0.3370 - sparse_catego - ETA: 1:27 - loss: 0.3370 - sparse_categorical_accur - ETA: 1:27 - loss: 0.3370 - sparse_categorical_accuracy: 0.8 - ETA: 1:27 - loss: 0.3370 - sparse_categorical_accuracy: - ETA: 1:26 - loss: 0.3370 - sparse_categorical_accuracy: 0.87 - ETA: 1:26 - loss: 0.3371 - sparse_categorical_accura - ETA: 1:26 - loss: 0.3370 - sparse_categorical_acc - ETA: 1:25 - loss: 0.3370 - sparse_categorica - ETA: 1:24 - loss: 0.3370 - sparse_categorica - ETA: 1:23 - loss: 0.3370 - sparse_categorical_accuracy: 0.8 - ETA: 1:23 - loss: 0.3370 - sparse_catego - ETA: 1:21 - loss: 0.3370 - sparse_categorical_accuracy: 0.87 - ETA: 1:21 - loss: 0.3370 - sparse_categ - ETA: 1:20 - loss: 0.3369 - sparse_categorical_acc - ETA: 1:19 - loss: 0.3369 - sparse_categorical_a - ETA: 1:18 - loss: 0.3369 - sparse_categorical_accur - ETA: 1:17 - loss: 0.3369 - sparse_categorical_acc - ETA: 1:17 - loss: 0.3369 - sparse_cat - ETA: 1:15 - loss: 0.3369 - sparse_categorical_ac - ETA: 1:14 - loss: 0.3369 - sparse_categorical_accuracy: 0 - ETA: 1:14 - loss: 0.3369 - sparse_categor - ETA: 1:13 - loss: 0.3369 - sparse_categorical_accurac - ETA: 1:12 - loss: 0.3369 - sparse_categorical_accur - ETA: 1:12 - loss: 0.3369 - sparse_categorical_accuracy: 0.87 - ETA: 1:12 - loss: 0.3369 - sparse_categorical_a - ETA: 1:11 - loss: 0.3370 - sparse_categorical_accu - ETA: 1:10 - loss: 0.3369 - sparse_categorical_accuracy: 0.878 - ETA: 1:10 - loss: 0.3369 - sparse_categoric - ETA: 1:09 - loss: 0.3369 - sparse_categorical_ac - ETA: 1:08 - loss: 0.3369 - sparse_categorical_accuracy: 0.878 - ETA: 1:08 - loss: 0.3369 - sparse_categorical_accuracy: 0.878 - ETA: 1:08 - loss: 0.3369 - sparse_categorical_accura - ETA: 1:07 - loss: 0.3369 - sparse_categorical_accuracy: 0.8 - ETA: 1:07 - loss: 0.3369 - sparse_categorical_accur - ETA: 1:07 - loss: 0.3369 - sparse_categorical_accur - ETA: 1:06 - loss: 0.3369 - sparse_categorical_accur - ETA: 1:05 - loss: 0.3369 - sparse_categorical_accuracy: 0.87 - ETA: 1:05 - loss: 0.3369 - sparse_categorical_accuracy: - ETA: 1:05 - loss: 0.3369 - sparse_ca - ETA: 1:03 - loss: 0.3 - ETA: 1:01 - loss: 0.3368 - sparse_categorical_accuracy: 0.87 - ETA: 1:01 - loss: 0.3368 - sparse_categorical_ac - ETA: 58s - loss: 0.3368 - sparse_categorical_accuracy - ETA: 58s - loss: 0.3368 - sparse_categorical_ - ETA: 57s - loss: 0.3368 - sparse_categorical_accuracy: 0. - ETA: 57s - loss: 0.3368 - ETA: 56s - loss: 0.3368 - spa - ETA: 56s - loss: 0.3368 - sparse_cate - ETA: 55s  - ETA: 54s - loss - ETA: 52s - loss: 0.3367 - sparse_categori - ETA: 52s - loss: 0.3367 - sparse_categorical_accuracy: 0.87 - ETA: 52s - loss: 0.3367 - sparse_catego - ETA:  - ETA: 46s - loss: 0.3366 - sparse_catego - ETA: 43s - loss: 0.3365 - sparse_ - ETA: 43s - loss: 0.3365 - sparse_categorical_accuracy: 0. - ETA: 42s - loss: 0.3365 - sparse_ca - ETA: 42s - loss: 0.3365 - sparse_categorical_ac - ETA: 41s - loss: 0.3365 - sparse_categorical_accuracy: 0. - ETA: 41s - loss: 0.3365 - ETA: 40s - loss: 0.3365 - sparse_catego - ETA: 39s - loss: 0.3365 - spars - ETA: 39s - loss: 0. - ETA: 37s - loss: 0.3364 - spa - ETA: 36s - loss: 0.3364 - sparse_catego - ETA: 36s - loss: 0.3364 - sparse_categorical_accuracy: 0. - ETA: 36s - loss: 0.3364 - sparse_catego - ETA: 35s - loss: 0.3364 - sparse_categorical_accura - ETA: 35s - loss: 0.3364 - sparse_categorical_accuracy: 0. - - ETA: 33s - loss: 0.3364 - sparse_categori - ETA: 32s - loss: 0.3364 - sparse_categorical_accuracy - ETA: 32s - loss: 0.3364 - sparse_categorical_accuracy: 0. - ETA: 28s - loss: 0.3363 - - ETA: 27s - loss: 0.3363 - sparse_categorical_accuracy: 0. - ETA: 27s - loss: 0.3363 - spa - ETA: 26s - loss:  - ETA: 25s - loss: 0.3363 - sparse_cate - ETA: 24s - loss: 0.33 - ETA: 23s - loss: 0.3362 - sparse_categorical_accuracy: 0. - ETA: 23s - loss: 0.3362 - spa - ETA: 22s - loss: 0.3362 - sparse_ - ETA: 17s - loss: 0.3362 - sparse_categorical_accu - ETA: 17s - loss: 0.3362 - sparse_cate - ETA: 16s - loss: 0.3361 - - ETA: 15s - loss: 0.3361 - sparse_categorical_accu - ETA: 15s - loss: 0.3362 - sparse_categorical_accuracy:  - ETA: 15s - loss: 0.3361 - sparse_ - ETA: 14s - lo - ETA: 12s - loss: 0.3361 - s - ETA: 11s - loss: 0.3361 - sparse_categorical_accuracy: 0. - ETA: 11s - loss: 0.3361 - sparse_categorical_accuracy: 0. - ETA: 11s - loss:  - ETA: 10s - loss: 0.3361 - sparse_categorical_accuracy: 0.87 - ETA: 10s - loss:  - ETA: 8s - loss: 0.3360 - sparse_categorical_accuracy: 0.8 - ETA: 8s - loss: 0.3361 - sparse_categorical_ - ETA: 7s - loss: 0.3360 - sparse_categorical_ac - ETA: 6s - loss: 0.3360 - sparse_categorical_accur - ETA: 5s - loss: 0.3360 - sparse_categorical_accuracy: 0.87 - ETA: 5s - loss: 0.3360 - sparse_categorical_acc - ETA: 4s - loss: 0.3359 - sparse_categorica - ETA: 3s - loss: 0.3359 - spars - ETA: 2s - loss: 0.3359 - sparse_categorical_accuracy: 0. - ETA: 1s - loss: 0.3359 - sparse_categorical_accuracy: 0.87 - ETA: 1s - loss: 0.3359 - sparse_categorical_accuracy: 0.87 - ETA: 1s - loss: 0.3359 - sparse_categorical_accura - ETA: 1s - loss: 0.3359 - sparse_categorica - ETA: 0s - loss: 0.3359 - sparse_categorical_accuracy: 0.8\n",
      "\n",
      "Epoch 00007: sparse_categorical_accuracy improved from 0.87523 to 0.87837, saving model to train/run_local/ckpt/weights-07-0.8784.h5\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 216s 14ms/step - loss: 0.3297 - sparse_categorical_accuracy: 0.8804 - val_loss: 0.3134 - val_sparse_categorical_accuracy: 0.8815ss: 0.3412 - sparse_categorical_accuracy: 0 - ETA: 3:37 - loss: 0.3323 - sparse_categorical_accuracy: 0 - ETA: 3:43 - loss: 0.3352 - sparse_categorical_accuracy: - ETA: 3:57 - loss: 0.3365 - sparse_categorical_accuracy: - ETA: 4:07 - loss: 0.3332 - sparse_categorical_accuracy: 0.8 - ETA: 4:17 - loss: 0.3333 - sparse_categorical_accuracy: 0.87 - ETA: 4:20 - loss: 0.3349 - sparse_categorical_ac - ETA: 4:26 - loss: 0.3299 - sparse_categorical_accuracy: 0.8 - ETA: 4:22 - loss: 0.3306 - sparse_cate - ETA: 4:08 - loss: 0.3295 - sparse_categorical_accu - ETA: 4:02 - loss: 0.3296 - sparse_categorical_accuracy: 0.87 - ETA: 4:02 - loss: 0.3306 - sparse_categorical_accura - ETA: 3:59 - loss: 0.3302 - sparse_categorical - ETA: 3:53 - loss: 0.3311 - - ETA: 3:43 - loss: 0.3315 - sparse_categorical_accuracy: 0.87 - ETA: 3:43 - loss: 0.3317 - sparse_categorical_accurac - ETA: 3:40 - loss: 0.3329 - sparse_cat - ETA: 3:37 - loss: 0.3323 - sparse_categorical_accuracy - ETA: 3:36 - loss: 0.3317 - sparse_categorical - ETA: 3:34 - loss: 0.3319 - sparse_categorical_accuracy: 0.879 - ETA: 3:33 - loss: 0.3319 - sparse_categorical_accuracy: 0.8 - ETA: 3:33 - loss: 0.3320 - sparse_categori - ETA: 3:30 - loss: 0.3317 - sparse_categorical_accuracy: 0. - ETA: 3:30 - loss: 0.3321 - sparse_categorical_accur - ETA: 3:29 - loss: 0.3317 - sparse_c - ETA: 3:26 - loss: 0.3317 - sparse_categorical_accuracy: 0.87 - ETA: 3:26 - loss: 0.3316 - sparse_categorical_accuracy: - ETA: 3:25 - loss: 0.3318 - sparse_categorical_a - ETA: 3:24 - loss: 0.3318 - sparse_categorical_accuracy - ETA: 3:23 - loss: 0.3317 - sparse_categorical_accur - ETA: 3:22 - loss: 0.3319 - sparse_categorical_accuracy: 0.879 - ETA: 3:22 -  - ETA: 3:18 - loss: 0.3316 - sparse_categorica - ETA: 3:16 - loss: 0.3312 - sparse_cat - ETA: 3:14 - loss: 0.3315 - sparse_categorical_ac - ETA: 3:13 - loss: 0.3314 - sparse_categorical_accura - ETA: 3:12 - loss: 0.3314 - sparse_categorical_accuracy: 0.879 - ETA: 3:12 - loss: 0.3314 - sparse_categorical_accu - ETA: 3:11 - loss: 0.3313 - sparse_categorical_accurac - ETA: 3:11 - loss: 0.3313 - sparse_categorical_ - ETA: 3:10 - loss: 0.3313 - sparse_categorical_acc - ETA: 3:08 - loss: 0.3312 - sparse_categ - ETA: 3:07 - loss: 0.3313 - sparse_categorical_a - ETA: 3:06 - loss: 0.3313 - sparse_categorical_accuracy: - ETA: 3:05 - loss: 0.3314 - sparse_categorical_accura - ETA: 3:04 - loss: 0.3315 - sparse_categorical_ - ETA: 3:03 - loss: 0.3317 - sparse_categ - ETA: 3:02 - loss: 0.3316 - sparse_categorical_accu - ETA: 3:01 - loss: 0.3318 - sparse_categorical_a - ETA: 3:00 - loss: 0.3317 - sparse_categ - ETA: 2:59 - loss: 0.3317 - sparse_categorical_accurac - ETA: 2:58 - loss: 0.3317 - sparse_categorical_accura - ETA: 2:57 - loss: 0.3318 - sparse_categorical_accuracy: 0.879 - ETA: 2:57 - loss: 0.3319 - sparse_categorical - ETA: 2:56 - loss: 0.3319 - sparse_ - ETA: 2:54 - loss: 0.3319 - sparse_categorical_accuracy: 0.87 - ETA: 2:54 - loss: 0.3317 - sparse_categorical_accu - ETA: 2:53 - loss: 0.3317 - sparse_categorical_accuracy: 0 - ETA: 2:53 - loss: 0.3317 - sparse_categorical_ac - ETA: 2:52 - loss: 0.3316 - sparse_categorical_accu - ETA: 2:51 - loss: 0.3316 - sparse_catego - ETA: 2:50 - loss: 0.3316 - sparse_catego - ETA: 2:48 - loss: 0.3317 - sparse_categorical_accuracy: 0.87 - ETA: 2:48 - loss: 0.3317 - sparse_categorical_accu - ETA: 2:47 - loss: 0.3316 - sparse_ca - ETA: 2:46 - loss: 0.3317 - sparse_categorical_accuracy: - ETA: 2:45 - loss: 0.3316 - sparse_categorica - ETA: 2:44 - loss: 0.3316 - sparse_categorical_accuracy: 0.88 - ETA: 2:44 - loss: 0.3317 - sparse_categorical_accuracy: 0.87 - ETA: 2:44 - loss: 0.3316 - sparse_categori - ETA: 2:43 - loss: 0.3317 - sparse_categorical_accuracy: 0.87 - ETA: 2:42 - loss: 0.3316 - sparse_categorical_accuracy: 0.87 - ETA: 2:42 - loss: 0.3317 - sparse_categorical_accuracy: 0.87 - ETA: 2:42 - loss: 0.3317 - sparse_categorical_accuracy: 0.8 - ETA: 2:42 - loss: 0.3316 - sparse_categorical_ac - ETA: 2:41 - loss: 0.3317 - sparse_cat - ETA: 2:40 - loss: 0.3317 - sparse_categorical_ - ETA: 2:39 - loss: 0.3316 - sparse_categorical - ETA: 2:38 - loss: 0.3316 - sparse_categorical_accuracy: 0.88 - ETA: 2:37 - loss: 0.3316 - sparse_categor - ETA: 2:36 - loss: 0.3316 - - ETA: 2:34 - loss: 0.3317 - sparse_categorical_accuracy: 0.880 - ETA: 2:34 - loss: 0.3317 - sparse_categor - ETA: 2:33 - loss: 0.3317 - sparse_categorical_accuracy - ETA: 2:32 - loss: 0.3317 - sparse_categorical_accuracy: 0.88 - ETA: 2:32 - loss: 0.3317 - sparse_categorical_accur - ETA: 2:32 - loss: 0.3317 - sparse_categorical_accura - ETA: 2:31 - loss: 0.3316 - sparse_categorical_ac - ETA: 2:30 - loss: 0.3317 - sparse_categorical_accur - ETA: 2:30 - loss: 0.3316 - sparse_categorical_accurac - ETA: 2:29 - loss: 0.3316 - sparse_categorical_accuracy: 0.880 - ETA: 2:29 - loss: 0.3316 - sparse_categorical_accur - ETA: 2:29 - loss: 0.3316 - sparse_categorical_accu - ETA: 2:28 - loss: 0.3316 - sparse_categorical_accuracy: 0.88 - ETA: 2:28 - loss: 0.3315 - sparse_cat - ETA: 2:26 - loss: 0.3315 - sparse_categorical_accuracy: 0.88 - ETA: 2:26 - loss: 0.3316 - sparse_categorical_a - ETA: 2:25 - loss: 0.3315 - sparse_categorical_accuracy: 0.88 - ETA: 2:25 - loss: 0.3315 - sparse_categorical_accuracy: 0.8 - ETA: 2:25 - loss: 0.3315 - sparse_categorical_a - ETA: 2:24 - loss: 0.3316 - sparse_categorical_accu - ETA: 2:23 - loss: 0.3317 - sparse_categorical_accuracy - ETA: 2:23 - loss: 0.3317 - sparse_categorical_accuracy - ETA: 2:22 - loss: 0.3316 - sparse_categorical_accuracy: 0. - ETA: 2:22 - loss: 0.3316 - sparse_categori - ETA: 2:21 - loss: 0.3316 - sparse_categorical_accuracy:  - ETA: 2:21 - loss: 0.3315 - sparse_cate - ETA: 2:19 - loss: 0.3315 - sparse_categorical_accuracy: 0.87 - ETA: 2:19 - loss: 0.3315 - sparse - ETA: 2:17 - loss: 0.3314 - sparse_categorical_accurac - ETA: 2:17 - loss: 0.3315 - sparse_categorical_accuracy: 0.87 - ETA: 2:17 - loss: 0.3315 - sp - ETA: 2:15 - loss: 0.3314 - sparse_categorical_accuracy: 0.87 - ETA: 2:15 - loss: 0.3314 - sparse_categorical_accuracy: 0.87 - ETA: 2:15 - loss: 0.3314 - sparse_categorical_accuracy: - ETA: 2:14 - loss: 0.3314 - sparse_categoric - ETA: 2:13 - loss: 0.3314 - sparse_categorical_accuracy: 0.87 - ETA: 2:13 - loss: 0.3314 - sparse_categorical_accu - ETA: 2:12 - loss: 0.3314 - sparse_categorical_ac - ETA: 2:11 - loss: 0.3314 - sparse_catego - ETA: 2:10 - loss: 0.3314 - sparse_categorical_accuracy: 0.87 - ETA: 2:10 - loss: 0.3314 - sparse_categorical_accuracy: 0.879 - ETA: 2:10 - loss: 0.3314 - ETA: 2:07 - loss: 0.3314 - sparse_categorical_accuracy: 0.87 - ETA: 2:07 - loss: 0.3314 - sparse_categorical - ETA: 2:06 - loss: 0.3313 - sparse_categorical_accu - ETA: 2:06 - loss: 0.3314 - sparse_cate - ETA: 2:04 - loss: 0.3313 - sparse_catego - ETA: 2:03 - loss: 0.3314 - sparse_categorical_accur - ETA: 2:02 - loss: 0.3313 - sparse_categorical_accuracy: 0. - ETA: 2:02 - loss: 0.3313 - sparse_categorical_accurac - ETA: 2:02 - loss: 0.3313 - sparse_categorica - ETA: 2:01 - loss: 0.3313 - sparse_categorical_accurac - ETA: 2:00 - loss: 0.3312 - sparse_categorical_accuracy: 0.87 - ETA: 2:00 - loss: 0.3313 - sparse_categorical_accuracy: 0.87 - ETA: 2:00 - loss: 0.3313 - sparse_categorical_accuracy: 0.87 - ETA: 2:00 - loss: 0.3313 - sparse_categorical_accuracy:  - ETA: 2:00 - loss: 0.3313 - sparse_categori - ETA: 1:58 - loss: 0.3313 - sparse_categorical_ - ETA: 1:58 - loss: 0.3312 - sparse_categorical_accura - ETA: 1:57 - loss: 0.3313 - sparse_categorical_accuracy: 0.87 - ETA: 1:57 - loss: 0.3313 - sparse_categorical_accuracy: 0 - ETA: 1:57 - loss: 0.3313 - sparse_categorical_ac - ETA: 1:56 - loss: 0.3312 - sparse_categorical_accuracy: 0.87 - ETA: 1:56 - loss: 0.3312 - sparse_ca - ETA: 1:54 - loss: 0.3313 - sparse_categorical_accuracy:  - ETA: 1:54 - loss: 0.3312 - sparse_categorical_ac - ETA: 1:53 - loss: 0.3312 - sparse_categorical_accur - ETA: 1:52 - loss: 0.3312 - sparse - ETA: 1:51 - loss: 0.3312 - sparse_categorical_accuracy: 0.879 - ETA: 1:51 - loss: 0.3312 - sparse_categorical_accuracy: 0.880 - ETA: 1:51 - loss: 0.3312 - sparse_categorical_accuracy: 0.880 - ETA: 1:51 - loss: 0.3312 - sparse_categorical_a - ETA: 1:50 - loss: 0.3312 - sparse_categorical_accuracy: 0.8 - ETA: 1:50 - loss: 0.3312 - sparse_categorical - ETA: 1:49 - loss: 0.3312 - sparse_categorical_accuracy: 0.879 - ETA: 1:48 - loss: 0.3311 - spa - ETA: 1:47 - loss: 0.3313 - sp - ETA: 1:45 - loss: 0.3313 - sparse_ca - ETA: 1:43 - los - ETA: 1:41 - loss: 0.3311 - sparse_categorical_ - ETA: 1:40 - loss: 0.3311 - sparse_categorical_accurac - ETA: 1:39 - loss: 0.3311 - sparse_categorical_a - ETA: 1:38 - loss: 0.3312 - sparse_categorical_accurac - ETA: 1:38 - loss: 0.3312 - sparse_categorical_accuracy: 0.87 - ETA: 1:38 - loss: 0.3312 - sparse_categorical_a - ETA: 1:37 - loss: 0.3312 - sparse_categorical_accuracy: 0.8 - ETA: 1:37 - loss: 0.3311 - sparse_categorical_accuracy: 0.8 - ETA: 1:36 - loss: 0.3311 - sparse_categorica - ETA: 1:35 - loss: 0.3312 - sparse_categorical_accuracy: 0. - ETA: 1:35 - loss: 0.3311 - sparse_categorical_accuracy: 0.879 - ETA: 1:35 - loss: 0.3311 - sparse_ca - ETA: 1:33 - loss: 0.3311 - sparse_categorical_accuracy: - ETA: 1:33 - loss: 0.3311 - sparse_categorical_accuracy: 0.87 - ETA: 1:33 - loss: 0.3311 - sparse_categorical_accur - ETA: 1:32 - loss: 0.3311 - sparse_categorical_acc - ETA: 1:32 - loss: 0.3311 - sparse_categorical_ - ETA: 1:31 - loss: 0.3310 - sparse_categorical_accuracy: 0.879 - ETA: 1:31 - loss: 0.3310 - sparse_categorica - ETA: 1:30 - loss: 0.3310 - sparse_categorical_acc - ETA: 1:29 - loss: 0.3310 - sparse_categorical_accura - ETA: 1:28 - loss: 0.3310 - sparse_categorical_ - ETA: 1:28 - loss: 0.3310 - spa - ETA: 1:26 - loss: 0.3311 - sparse_categorical_accuracy: 0.8 - ETA: 1:25 - loss: 0.3311 - sparse_categorical_accuracy: 0 - ETA: 1:25 - loss: 0.3311 - sparse_categorical_accuracy: 0.87 - ETA: 1:25 - loss: 0.3311 - sparse - ETA: 1:23 - loss: 0.3310 - sparse_categorical_accuracy: 0.87 - ETA: 1:23 - loss: 0.3310 - sparse_categorical_accur - ETA: 1:23 - loss: 0.3310 - sparse_categorical_accu - ETA: 1:22 - loss: 0.3310 - sparse_categorical_accuracy: 0.87 - ETA: 1:22 - loss: 0.3310 - sparse_categorical_ - ETA: 1:21 - loss: 0.3310 - sparse_categorical_accura - ETA: 1:20 - loss: 0.3310 - sparse_categorical_accura - ETA: 1:19 - loss: 0.3309 - sparse_cat - ETA: 1:18 - loss: 0.3309 - sparse_categorical_ac - ETA: 1:17 - loss: 0.3309 - sparse_categorical_accura - ETA: 1:17 - loss: 0.3309 - sparse_categorical - ETA: 1:16 - loss: 0.3309 - sparse_categorical_accuracy: 0.87 - ETA: 1:16 - loss: 0.3308 - sparse_categorical_acc - ETA: 1:15 - loss: 0.3309 - sparse_categorical_accu - ETA: 1:14 - loss: 0.3309 - sparse_categorical_accuracy: 0.879 - ETA: 1:14 - loss: 0.3309 - sparse_categorical_accu - ETA: 1:14 - loss: 0.3309 - sparse_categorical_accu - ETA: 1:13 - loss: 0.3309 - sparse_cate - ETA: 1:11 - loss: 0.3309 - sparse - ETA: 1:10 - loss: 0.3309 - sparse_categorical_accuracy: 0.879 - ETA: 1:10 - loss: 0.3308 - sparse_categorical_accu - ETA: 1:09 - loss: 0.3308 - sparse_categorical_accu - ETA: 1:08 - loss: 0.3308 - sparse_categorical_accuracy: 0.87 - ETA: 1:08 - loss: 0.3308 - sparse_categorical_a - ETA: 1:07 - loss: 0.3308 - sparse_categorical_acc - ETA: 1:06 - loss: 0.3308 - sparse_ca - ETA: 1:05 - loss: 0.3308 - sparse_categorical_ - ETA: 1:04 - loss: 0.3308 - sparse_categorical_accuracy:  - ETA: 1:04 - loss: 0.3308 - sparse_categorical_accu - ETA: 1:03 - loss: 0.3308 - sparse_categorical_accuracy: 0 - ETA: 1:03 - loss: 0.3307 - sparse_categorical_accuracy: 0.8 - ETA: 1:03 - loss: 0.3307 - sparse_categorical_accuracy: 0. - ETA: 1:02 - loss: 0.3307 - sparse_categorical_accuracy:  - ETA: 1:02 - loss: 0.3307 - sparse_categorical_accu - ETA: 1:01 - loss: 0.3307 - sparse_categorical_ac - ETA: 1:01 - - ETA: 59s - loss: 0.3307 - sparse_categorical_accuracy: 0. - ETA: 58s - loss: 0.3307 - sparse_ca - ETA: 58s - loss: 0.3307 - sparse_categorical_accuracy:  - ETA: 58s - loss: 0.3307 - sparse_catego - ETA: 57s - loss: 0.3307 - sparse_categorical_accuracy: 0. - ETA: 57s - loss: 0.3306 - sparse_categorical_accuracy: 0. - ETA: 57s - loss - ETA: 55s - loss: 0.3306 - sparse_categorical_accuracy: 0. - ETA: 55s - loss: 0.3306 - spars - ETA: 54s - loss: 0.3306 - sparse_categorical_accura - ETA: 54s - loss: 0.3306 - sparse_categorical_accuracy: 0.88 - ETA: 54s - loss: 0.3306 - spars - ETA: 51s - loss: 0.3305 - sparse_categorical_accuracy: 0. - ETA: 51s - loss: 0.3305 - sparse_categorical_accuracy: 0. - ETA: 51s - loss: 0.3305 - sparse_ca - ETA: 50s - loss: 0.3305 - sparse_cate - - ETA: 48s - loss: 0.3304 - spa - ETA: 47s -  - ETA: 45s - loss: 0.33 - ETA: 42s - loss: 0.3303 - spa - ETA: 41s - loss: 0.3303 - sparse_categorical_accuracy: 0. - ETA: 41s - loss: 0.3303 - sparse_categorical_accuracy: 0. - ETA: 41s - loss: 0.3303 - sparse_categorical_accuracy: 0.88 - ETA: 41s - loss: 0.3303 - sparse_categorical_accuracy: 0. - ETA: 41s - loss: 0.3303 - sparse_categorical_accu - ETA: 41s - loss: 0.3304 - sparse_categorical_accuracy:  - ETA: 40s - lo - ETA: 37s - loss: 0.3303 - sparse_categorical_accura - ETA: 37s - loss: 0.3303 - sparse_categorical_accuracy: 0. - ETA: 37s - loss: 0.3303 - sparse_categorical_accuracy: 0.88 - ETA: 37s -  - ETA: 32s - loss: 0.3302 - sparse_categorical_accuracy: 0. - ETA: 31s - loss: 0.3302 - sparse_categorical_accuracy:  - ETA: 31s - loss: 0.3302 - spars - ETA: 31s - loss: 0.3302 - sparse_categorical_ - ETA: 30s - loss: 0.3302 - sparse_categorical_ - ETA: 30s - loss: 0.3302 - - ETA: 29s - loss:  - ETA: 22s - loss: 0.3301 - sparse_catego - ETA: 19s - loss: 0.3300 - sparse_categorical_accuracy: 0. - ETA: 19s - loss: 0.3300 - sparse_categorical_accuracy: 0. - ETA: 19s - loss: 0.3300 - sparse_categorical_ - ETA: 19s - loss: 0.3300 - sparse_ca - ETA: 18s - loss: 0.3300 - sparse_categorical_accuracy: 0. - ETA: 18s - loss: 0.3300 - sparse_cate - ETA: 17s - loss: 0.3300 - sparse_categorical_accuracy: 0. - ETA: 17s -  - ETA - ETA: 14s - loss: 0.3300 - sparse_ca - ETA: 13s - loss: 0.3300 - - ETA: 12s - loss: 0.3299 - spars - ETA: 11s - loss: 0.3299 - sparse_categorical_accuracy: 0. - ETA: 11s - loss: 0.3299 - sparse_categorical_accuracy: 0. - ETA: 11s - loss: 0.3299 - sparse_catego - ETA: 10s - loss: 0.3298 - sparse_categorical_accuracy: 0. - ETA: 10s - loss: 0.3299 - sparse_categorical_accuracy:  - ETA: 10s - loss: 0.3299 - sparse_categorical_accuracy: 0. - ETA: 10s - loss: 0.3298 - sparse_categorical_ - ETA: 9s - loss: 0.3299 - sparse_categorical_accura - ETA: 8s - loss: 0.3298 - sparse_categorical_accuracy: - ETA: 8s - loss: 0.3298 - sparse_categorical_ - ETA: 7s - loss: 0.3298 - sparse_categoric - ETA: 6s - loss: 0.3299 - sparse_categorical_accuracy: 0.88 - ETA: 6s - loss: 0.3298 - sparse_categorical - ETA: 5s - loss: 0.3298 - ETA: 2s - loss: 0.3298 - sparse_categorical_ac - ETA: 2s - loss: 0.3298 - sparse_categorical_accuracy: 0.88 - ETA: 2s - loss: 0.3297 \n",
      "\n",
      "Epoch 00008: sparse_categorical_accuracy improved from 0.87837 to 0.88041, saving model to train/run_local/ckpt/weights-08-0.8804.h5\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 219s 15ms/step - loss: 0.3242 - sparse_categorical_accuracy: 0.8826 - val_loss: 0.3100 - val_sparse_categorical_accuracy: 0.88386 - sparse_categorical_accuracy: 0.88 - ETA: 3:31 - loss: 0.3354 - sparse_categorical_accuracy:  - ETA: 3:32 - loss: 0.3334 - sparse_categorica - ETA: 3:31 - loss: 0.3307 - sparse_catego - ETA: 3:2 - ETA: 3:27 - loss: 0.3300 - sparse_categorical_accuracy: 0.88 - ETA: 3:27 - los - ETA: 3:24 - loss: 0.3290 - sparse_categorical_acc - ETA: 3:24 - loss: 0.3293  - ETA: 3:21 - loss: 0.3283 - sparse_categorical_accuracy: 0.8 - ETA: 3:21 - loss: 0.3283 - sparse_categorical_acc - ETA: 3:20 - loss: 0.3284 - sparse_categorical_ac - ETA: 3:19 - loss: 0.3285 - sparse_catego - ETA: 3:18 - loss: 0.3282 - sparse_categorical_acc - ETA: 3:17 - loss: 0.3287 - sparse_categorical_accur - ETA: 3:16 - loss: 0.3285 - sparse_categorical_accuracy: 0.88 - ETA: 3:16 - loss: 0.3285 - sparse_categorical_accuracy: 0.881 - ETA: 3:16 - loss: 0.3285 - sparse - ETA: 3:14 - loss: 0.3284 - sparse_categorical_accuracy: 0.88 - ETA: 3:14 - loss: 0.3284 - sparse_categorical_accur - ETA: 3:13 - loss: 0.3284 - sparse_ca - ETA: 3:12 - loss: 0.3285 - sparse_categorical_acc - ETA: 3:11 - loss: 0.3285 - sparse_categoric - ETA: 3:10 - loss: 0.3283 - sparse_categorical_accuracy: 0.8 - ETA: 3:10 - loss: 0.3283 - sparse_categorical_accuracy: 0.88 - ETA: 3:10 - loss: 0.3283 - sparse_categorical_acc - ETA: 3:09 - loss: 0.3284 - sparse_categorical_accuracy: 0.88 - ETA: 3:09 - loss: 0.3284 - sparse_categorical_accuracy: 0 - ETA: 3:09 - loss: 0.3285 - sparse_categorical_accuracy: 0.8 - ETA: 3:09 - loss: 0.3283 - sparse_categorical_accuracy: 0.88 - ETA: 3:09 - loss: 0.3282 - sparse_ca - ETA: 3:11 - loss: 0.3283 - sparse_categ - ETA: 3:10 - loss: 0.3280 - sparse_categorical_accuracy: 0. - ETA: 3:09 - loss: 0.3281 - sparse_categorical_accu - ETA: 3:09 - loss: 0.3277 - sparse_categorical_accur - ETA: 3:08 - loss: 0.3280 - sparse_categorical_accuracy: 0.88 - ETA: 3:08 - loss: 0.3278 - sparse_categorical_accuracy: 0.88 - ETA: 3:08 - loss: 0.3277 - sparse_categorical_ - ETA: 3:07 - loss: 0.3278 - sparse_cat - ETA: 3:06 - loss: 0.3278 - sparse_categorical_accur - ETA: 3:05 - loss: 0.3275 - sparse_categorical_accuracy: 0.88 - ETA: 3:05 - loss: 0.3274 - sparse_categorical_a - ETA: 3:04 - loss: 0.3277 - sparse_categorical_accuracy: 0.88 - ETA: 3:03 - loss: 0.3278 - sparse_ca - ETA: 3:02 - loss: 0.3277 - sparse_categorical_accura - ETA: 3:01 - loss: 0.3276 - sparse_categorical_accuracy: 0. - ETA: 3:01 - loss: 0.3276 - sparse_categorical_accuracy: 0.8 - ETA: 3:01 - loss: 0.3 - ETA: 2:58 - loss: 0.3272 - spars - ETA: 2:56 - loss: 0.3272 - sparse_categori - ETA: 2:55 - loss: 0.3271  - ETA: 2:53 - loss: 0.3269 - sparse_categorical_accuracy: 0.88 - ETA: 2:53 - loss: 0.3270 - sparse_categorical_accuracy: 0.88 - ETA: 2:52 - loss: 0.3272 - sparse_categorical_accuracy - ETA: 2:52 - loss: 0.3271 - sparse_categorical_accuracy: 0.88 - ETA: 2:52 - loss: 0.3270 - sparse_categori - ETA: 2:51 - loss: 0.3270 - sparse_categorical_accuracy: 0.881 - ETA: 2:51 - loss: 0.3270 - sparse_categorical_ - ETA: 2:49 - loss: 0.3268 - sparse_categorical_accuracy: 0.88 - ETA: 2:49 - loss: 0.3269 - sparse_categorical_accuracy: 0.881 - ETA: 2:49 - loss: 0.3270 - sparse_categorical_accu - ETA: 2:49 - loss: 0.3270 - sparse_categorical_accuracy: 0.8 - ETA: 2:48 - loss: 0.3270 - sparse_categorical_accur - ETA: 2:48 - loss: 0.3270 - sparse_categorical_accu - ETA: 2:47 - loss: 0.3270 - sparse_categorical_ac - ETA: 2:46 - loss: 0.3269 - sparse_categorical_acc - ETA: 2:45 - loss: 0.32 - ETA: 2:43 - loss: 0.3268 - sparse_categor - ETA: 2:42 - loss: 0.3267 - sparse_categorical_accuracy: 0.881 - ETA: 2:42 - loss: 0.3267 - sparse_categor - ETA: 2:40 - loss: 0.3268 - sparse_categorical_accuracy: 0.88 - ETA: 2:40 - loss: 0.3268 - sparse_categorical_accura - ETA: 2:40 - loss: 0.3269 - sparse_categorical_accuracy: 0 - ETA: 2:39 - loss: 0.3268 - sparse_categorical_accuracy: 0.881 - ETA: 2:39 - loss: 0.3268 - sparse_cate - ETA: 2:38 - loss: 0.3268 - sparse_categorical_accuracy: 0.8 - ETA: 2:37 - loss: 0.3267 - sparse_categorical_accu - ETA: 2:37 - loss: 0.3266 - sparse_categorical_accur - ETA: 2:36 - loss: 0.3268 - sparse_categorical_accurac - ETA: 2:36 - loss: 0.3267 - sparse_categorical_accura - ETA: 2:35 - loss: 0.3267 - sparse_categorical_accuracy: 0.88 - ETA: 2:35 - loss: 0.3267 - sparse_categorical_accuracy: 0.881 - ETA: 2:35 - loss: 0.3266 - sparse_categorica - ETA: 2:34 - loss: 0.3267 - sparse_categorical_accura - ETA: 2:33 - loss: 0.3267 - sparse_categorical_accu - ETA: 2:32 - loss: 0.3267 - sparse_categorical_ - ETA: 2:31 - loss: 0.3268 - sparse_categorica - ETA: 2:30 - loss: 0.3268 - sparse_cate - ETA: 2:29 - loss: 0.3267 - sparse_categorical_ac - ETA: 2:28 - loss: 0.3266 - sparse_categorical_accuracy: 0.881 - ETA: 2:28 - loss: 0.3266 - sparse_categorical_accura - ETA: 2:27 - loss: 0.3265 - spars - ETA: 2:25 - loss: 0.3266 - sparse_categorical_accuracy: 0 - ETA: 2:25 - loss: 0.3266 - spars - ETA: 2:23 - loss: 0.3266 - sparse_categorical_accurac - ETA: 2:23 - loss: 0.3265 - sparse_categorical_accuracy: 0.88 - ETA: 2:23 - loss: 0.3266 - sparse_categorical_accuracy: 0 - ETA: 2:22 - loss: 0.3266 - sparse_categorical_accuracy: 0.88 - ETA: 2:22 - loss: 0.3266 - sparse_categorical_accuracy: 0.881 - ETA: 2:22 - loss: 0.3265 - sparse_categorical_ac - ETA: 2:21 - loss: 0.3265 - sparse_c - ETA: 2:20 - loss: 0.3264 - sparse_categori - ETA: 2:19 - loss: 0.3264 - sparse_categorical_accuracy: 0.88 - ETA: 2:18 - loss: 0.3264 - sparse_categorical_acc - ETA: 2:18 - loss: 0.3263 - sparse_categorical_accuracy: 0.88 - ETA: 2:18 - loss: 0.3263 - sparse_categorical_a - ETA: 2:17 - loss: 0.3263 - sparse_categorical_accura - ETA: 2:16 - loss: 0.3262 - sparse_categorical_accuracy: 0.88 - ETA: 2:16 - loss: 0.3263 - sparse_categor - ETA: 2:15 - loss: 0.3262 - sparse_categorical_accuracy: 0.88 - ETA: 2:15 - loss: 0.3262 - sparse_categorical - ETA: 2:14 - loss: 0.3262 - sparse_categorical_a - ETA: 2:12 - loss: 0.3261 - sparse_categorical_accuracy: 0 - ETA: 2:12 - loss: 0.3261 - sparse_categ - ETA: 2:11 - loss: 0.3261 - sparse_categorical_accuracy: 0.8 - ETA: 2:11 - loss: 0.3262 - sparse_categorical_accuracy: 0.8 - ETA: 2:11 - loss: 0.3261 - sparse_ - ETA: 2:10 - loss: 0.3261 - sparse_categorical_accuracy: 0.88 - ETA: 2:10 - loss: 0.3261 - sparse_categorical_a - ETA: 2:09 - loss: 0.3261 - sparse_categorical_accura - ETA: 2:09 - loss: 0.3261 - sparse_categorical_accuracy: 0.88 - ETA: 2:08 - loss: 0.3261 - sparse_categorical_accuracy: 0.881 - ETA: 2:08 - loss: 0.3261 - sparse_categorical_accur - ETA: 2:08 - loss: 0.3260 - sparse_categorical_accuracy: 0.8 - ETA: 2:08 - loss: 0.3261 - sp - ETA: 2:06 - loss: 0.3260 - sparse_categorical_accur - ETA: 2:05 - loss: 0.3260 - sparse_categorica - ETA: 2:04 - loss: 0.3260 - sparse_categorical_accuracy: 0.88 - ETA: 2:04 - loss: 0.3260 - sparse_categorical_accura - ETA: 2:03 - loss: 0.3260 - sparse_categorical_accuracy - ETA: 2:03 - loss: 0.3259 - sparse_categorical_a - ETA: 2:02 - loss: 0.3260 - sparse_categorical_accuracy: 0.88 - ETA: 2:02 - loss: 0.3260 - sparse_categorical_a - ETA: 2:01 - loss: 0.3260 - sparse_categorical_accuracy: 0.88 - ETA: 2:01 - loss: 0.3259 - sparse_categorical_accurac - ETA: 2:00 - loss: 0.3260 - sparse_categorical_accuracy: 0.881 - ETA: 2:00 - loss: 0.3259 - sparse_categorical - ETA: 1:59 - loss: 0.3259 - sparse_categorical_a - ETA: 1:58 - loss: 0.3260 - sparse_categorical_accuracy: 0.88 - ETA: 1:58 - loss: 0.3260 - sparse_categorical_accuracy: 0.8 - ETA: 1:58 - loss: 0.3260 - sparse_categorical_accuracy: 0.88 - ETA: 1:58 - loss: 0.3259 - sparse_categorical_accuracy: 0. - ETA: 1:58 - loss: 0.3260 - sparse_categorical_accuracy: 0 - ETA: 1:57 - loss: 0.3260 - sparse_categorical_accuracy: 0.88 - ETA: 1:57 - loss: 0.3260 - sparse_c - ETA: 1:56 - loss: 0.3260 - sparse_categorical_accuracy: 0.8 - ETA: 1:56 - loss: 0.3260 - sparse_categorical_accuracy: 0.8 - ETA: 1:55 - loss: 0.3260 - sparse_ - ETA: 1:54 - loss: 0.3260 - sparse_categorical_accuracy: - ETA: 1:53 - loss: 0.3259 - sparse_categorical_accur - ETA: 1:53 - loss: 0.3259 - sparse_categorical_accuracy: 0. - ETA: 1:52 - loss: 0.3259 - sparse_categ - ETA: 1:51 - loss: 0.3259 - sparse_categorical_accuracy: 0.88 - ETA: 1:51 - loss: 0.3259 - sparse_categorical_a - ETA: 1:50 - loss: 0.3258 - sparse_categorical_accuracy: 0.88 - ETA: 1:50 - loss: 0.3259 - sparse_catego - ETA: 1:48 - loss: 0.3259 - spar - ETA: 1:47 -  - ETA: 1:43 - loss: 0.3258 - sparse_categorical_accuracy: 0.8 - ETA: 1:43 - loss: 0.3258 - sparse_categorical_ac - ETA: 1:43 - loss: 0.3257 - sparse_categorical_accu - ETA: 1:42 - loss: 0.3257 - sparse_categorical_ - ETA: 1:41 - loss: 0.3257 - sparse_categ - ETA: 1:39 - loss: 0.3256 - sparse_categorical_accur - ETA: 1:39 - loss: 0.3256 - sparse_categorical_accuracy: 0.88 - ETA: 1:39 - loss: 0.3256 - sparse_catego - ETA: 1:37 - loss: 0.3256 - sparse_categorical_accuracy: - ETA: 1:37 - loss: 0.3255 - sparse_categorical_accur - ETA: 1:36 - loss: 0.3255 - sparse_catego - ETA: 1:35 - loss: 0.3255 - sparse_categorical_accuracy: 0.88 - ETA: 1:35 - loss: 0.3255 - sparse_categorical_accuracy: 0.88 - ETA: 1:35 - loss: 0.3255 - sparse_categorical_accuracy: 0.882 - ETA: 1:35 - loss: 0.3255 - sparse_categorical_accuracy: 0.882 - ETA: 1:35 - loss: 0.3255 - sparse_categorical_accuracy: 0.882 - ETA: 1:35 - loss: 0.3255 - sparse_categorical_accuracy - ETA: 1:34 - loss: 0.3255 - sparse_categorical_accura - ETA: 1:33 - loss: 0.3255 - sparse_categorical - ETA: 1:32 - loss: 0.3254 - sparse_categorical_accuracy: 0.8 - ETA: 1:32 - loss: 0.3255 - sparse_categorical_accura - ETA: 1:32 - loss: 0.3255 - sparse_categorical_accuracy: 0.8 - ETA: 1:32 - loss: 0.3255 - sparse_categorical_accura - ETA: 1:31 - loss: 0.3255 - sp - ETA: 1:29 - loss: 0.3254 - sparse_categorical_accu - ETA: 1:28 - loss: 0.3255 - sparse_categorical_ - ETA: 1:27 - loss: 0.3255 - sparse_categorical_accuracy: 0.88 - ETA: 1:27 - loss: 0.3254 - sparse_categorical_a - ETA: 1:26 - loss: 0.3254 - sparse_categorical_accuracy - ETA: 1:26 - loss: 0.3254 - sparse_categorical_accurac - ETA: 1:25 - loss: 0.3255 - sparse_ - ETA: 1:24 - loss: 0.3255 - sparse_categorical_accuracy: 0.88 - ETA: 1:23 - loss: 0.3255 - sparse_categorical_accuracy: - ETA: 1:23 - loss: 0.3254 - sparse_categorical_ac - ETA: 1:22 - loss: 0.3254 - sparse_categorical_accu - ETA: 1:21 - loss: 0.3254 - sparse_categorica - ETA: 1:20 - loss: 0.3254 - sparse_categorical_accuracy: 0.88 - ETA: 1:20 - loss: 0.3254 - sparse_categori - ETA: 1:19 - loss: 0.3253 - sparse_categorical_accuracy: 0.88 - ETA: 1:19 - loss: 0.3254 - sparse_categorical_accur - ETA: 1:18 - loss: 0.3254 - sparse_categorical_accuracy: 0.88 - ETA: 1:18 - loss: 0.3254 - sparse_categori - ETA: 1:17 - loss: 0.3254 - sparse_categorical_accuracy: 0.88 - ETA: 1:17 - loss: 0.3253 - sparse_categorical_accuracy: 0.88 - ETA: 1:17 - loss: 0.3253 - sparse_categorical_accuracy: 0.88 - ETA: 1:17 - loss: 0.3253 - sparse_categorical_accuracy: 0.88 - ETA: 1:17 - loss: 0.3254 - sparse_categorical_accuracy: 0.882 -  - ETA: 1:13 - loss: 0.3253 - sparse_categorical_accur - ETA: 1:12 - loss: 0.3252 - sparse_categorical_accuracy: 0.88 - ETA: 1:12 - loss: 0.3253 - sparse_c - ETA: 1:11 - loss: 0.3252 - sparse_categorical_accuracy: 0. - ETA: 1:11 - loss: 0.3252 - sparse_categorical_accurac - ETA: 1:11 - loss: 0.3252 - sparse_categorical_acc - ETA: 1:10 - loss: 0.3252 - sparse_categorical_accuracy: 0.88 - ETA: 1:10 - loss: 0.3252 - sparse_categorical_accuracy: 0.882 - ETA: 1:10 - loss: 0.3252 - sparse_categorical_accuracy: - ETA: 1:09 - loss: 0.3252 - sparse_categorical - ETA: 1:08 - loss: 0.3252 - sparse_categorical_accura - ETA: 1:08 - loss: 0.3252 - sparse_categorical_ - ETA: 1:07 - loss: 0.3252 - sparse_categorical_accuracy: 0. - ETA: 1:07 - loss: 0.3252 - sparse_ca - ETA: 1:05 - loss: 0.3251 - sparse_categorical_accuracy: 0. - ETA: 1:05 - loss: 0.3251 - sparse_categorical_accuracy: 0.88 - ETA: 1:05 - loss: 0.3251 - sparse_categorical_accuracy: 0.882 - ETA: 1:05 - loss: 0.3251 - sparse_categorical_accu - ETA: 1:04 - loss: 0.3251 - sparse_categorical_ - ETA: 1:03 - loss: 0.3251 - sparse_categorical_accur - ETA: 1:02 - loss: 0.3251 - sparse_categorical_accuracy: 0. - ETA: 1:02 - loss: 0.3251 - sparse_categorical_accur - ETA: 1:01 - loss: 0.3251 - sparse_categorical - ETA: 1:00 - loss: 0.3251 - sparse_categorical_accuracy: 0. - ETA: 1:00 - loss: 0.3251 - sparse_categorical_accuracy  - ETA: 58s - loss: 0.3250 - sparse_categorical_accuracy: 0. - ETA: 58s - loss: 0.3250 - spars - ETA: 57s - loss: 0.3250 - sparse_categorical_ - ETA: 56s - loss: 0.3251 - sparse_cate - ETA: 56s - loss: 0.3250 - sparse_categorical_accura - ETA: 55s - loss: 0.3250 - sparse_catego - ETA: 52s - loss: 0.3250 - sparse_categorical_accuracy:  - ETA: 52s - loss: 0.3250 - sparse_categorical_accuracy: 0.88 - ETA: 52s - loss: 0.3250 - sparse_catego - ETA: 52s - loss: 0.3250 - sparse_categorical_accuracy: 0. - ETA: 51s - loss: 0.3249 - sparse_categorical_accura - ETA: 51s - loss: 0.3250 - spa - ETA: 50s - loss: 0.3250 - sparse_categorical_accuracy - ETA: 50s - loss: 0.3250 - sparse_categorical_accuracy:  - ETA: 50s - loss: 0.3249 - sparse_cate - ETA: 49s - loss: 0.3250 - sparse_categorical_accuracy: 0.88 - ETA: 49s - loss: 0.3250 - sparse_ca - ETA: 48s - loss: 0.3249 - sparse_categorical_accuracy: 0.88 - ETA: 48s - loss: 0.3250 - sparse_ca - ETA: 48s - loss: 0.3249 - sparse_categorical_ - ETA: 47s - loss: 0.3249 - sparse_categorical_accuracy:  - ETA: 47s - loss: 0.3249 - sparse_categorical_accuracy: 0. - ETA: 47s - loss: 0.3249 - sparse_categorical_accuracy: 0.88 - ETA: 47s - loss: 0.3249 - spa - ETA: 46s - loss: 0.3248 - sparse_catego - ETA: 45s - loss: 0.3249 - s - ETA: 44s - loss: 0.3249 - sparse_categorica - ETA: 44s - loss: 0.3249 - sparse_categorical_accuracy - ETA: 43s - loss: 0.3249 - sparse_categorical_accuracy: 0. - ETA: 43s - loss: 0.3249 - sparse_categorical_accuracy: 0. - ETA: 43s - loss: 0.3249 - sparse_categorical_accuracy - ETA: 43s - loss: 0.3248 - sparse_categorical_accuracy:  - ETA: 43s - loss: 0.3248 - sparse_categorical_accuracy: 0.88 - ETA:  - ETA: 41s - loss: 0.3249 - sparse_ca - ETA: 40s - loss - ETA: 39s - loss: 0.3248 - sparse_categorical_accuracy: 0. - ETA: 39s - loss: 0.3248 - sparse_categorical_accu - ETA: 38s - loss: 0.3248 - sparse_categori - E - ETA: 36s - loss: 0.3247 - sparse_categorical_ac - ETA:  - ETA: 34s - loss: 0.3247 - sparse_categorica - ETA: 34s - loss: 0.32 - ETA: 32s - loss: 0.3246 - sparse_categorical_accuracy: 0. - ETA: 32s - loss: 0.3246 - sparse_categorical_accuracy: 0. - ETA: 32s - loss: 0. - ETA: 31s - loss: 0.3246 - sparse_categorical_accuracy: 0.88 - ETA: 31s - loss:  - ETA: 29s - loss: 0.3245 - - ETA: 27s - loss: 0.3244 - sparse_categorical_accuracy: 0. - ETA: 26s - loss: 0.3244 - sparse_categori - ETA: 26s - loss: 0.3244 - sparse_categorical_accuracy: 0. - ETA: 26s - loss: 0.3244 - sparse_catego - ETA: 25s - loss: 0.3244 - sparse_catego - ETA: 24s - loss: 0.3244 - sparse_ca - ETA: 24s - loss: 0.3244 - sparse_categorical_accuracy: 0. - ETA: 23s - loss: 0.3244 - sparse_categorical_accuracy: 0. - - ETA: 21s - loss: 0.3244 - sparse_categorical_accuracy:  - ETA: 21s - loss: 0.3244 - sparse_categorical_accuracy: 0.88 - ETA: 21s - loss: 0.3244 - sparse_categorica - ETA: 21s - loss: 0.3244 - sparse_categorical_accuracy: 0. - ETA: 21s - loss: 0.3244 - - ETA: 19s - loss: 0.3244 - sparse_ - ETA: 19s - loss: 0.3244 - sparse_categorical_accuracy: 0. - ETA: 19s - loss: 0.3244 - sparse_categorical_accura - ETA: 18s - loss: 0.32 - ETA: 17s - loss: 0.3244 - s - ETA: 16s - loss: 0.3244 - sparse_catego - ETA: 15s - loss - ETA: 14s - loss: 0.3244 - s - ETA: 13s - loss: 0.3243 - sparse_catego - ETA: 12s - loss: 0.3244 - sparse_categorical_accuracy: 0. - ETA: 12s - loss: 0.3244 - sparse_categorical_accu - ETA: 12s - loss: 0.3244 - sparse_categorical_accuracy: 0. - ETA: 12s -  - ETA: 11s - loss: 0.3243 - sparse_categori - ETA: 10s - loss: 0.3243 - sparse_catego - ETA: 9s - loss: 0.3243 - sparse_categorical_accuracy: 0.882 - ETA: 9s - loss: 0.3243 - sparse_categorical_accurac - ETA: 9s - loss: 0.3243 - sparse_categorical_accuracy: 0 - ETA: 8s - loss: 0.3243 - sparse_categorical_accuracy: 0.8 - ETA: 8s - loss: 0.3243 - sparse_categorical - ETA: 7s - loss: 0.3243 - sparse_categorical_accur - ETA: 7s - loss: 0.3242 - sparse_categorical_accur - ETA: 6s - loss: 0.3242 - sparse_categorical_acc - ETA: 5s - loss: 0.3242 - sparse_categorical - ETA: 4s - loss: 0.3243 - sparse_ca - ETA: 3s - loss: 0.3242 - sparse_categorical_accurac - ETA: 2s - loss: 0.3243 - sparse_categorical_accurac - ETA: 2s - loss: 0.3242 - sparse_categorical_accuracy: 0.88 - ETA: 2s - loss: 0.3242 - sparse_categorical_accu - ETA: 1s - loss: 0.3242 - sparse_catego - ETA: 0s - loss: 0.3242 - sparse_categorical_accuracy: 0.88\n",
      "\n",
      "Epoch 00009: sparse_categorical_accuracy improved from 0.88041 to 0.88255, saving model to train/run_local/ckpt/weights-09-0.8826.h5\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 219s 15ms/step - loss: 0.3184 - sparse_categorical_accuracy: 0.8843 - val_loss: 0.3059 - val_sparse_categorical_accuracy: 0.8854 3:25 - loss: 0.3177 - sparse_categorical_accuracy: 0.88 - ETA: 3:26 - loss: 0.3177 - sparse_categorical_accuracy: 0.88 - ETA: 3:27 - loss: 0.3177 - sparse_c - ETA: 3:35 - loss: 0.3220 - sparse_categorical_accuracy: 0.8 - ETA: 3:35 - loss: 0.3228 - sparse_categorical_accu - ETA: 3:37 - loss: 0.3236 - sparse_categorical_ - ETA: 3:35 - loss: 0.3224 - sparse_categorical_a - ETA: 3:33 - loss: 0.3229 - sparse_categorical_accuracy: 0.88 - ETA: 3:33 - loss: 0.3221 - sparse_categorical_accuracy: 0. - ETA: 3:33 - loss: 0.3212 - sparse_categorical_accu - ETA: 3:32 - loss: 0.3225 - sparse_categorical_accuracy - ETA: 3:31 - loss: 0.3219 - sparse_categorical_accuracy:  - ETA: 3:30 - loss: 0.3214 - sparse_categorical_accuracy: 0.88 - ETA: 3:30 - loss: 0.3217 - sparse_cate - ETA: 3:28 - loss: 0.3215 - sparse_categorical_accuracy: 0. - ETA: 3:24 - loss: 0.3210 - sparse_categorical_accu - ETA: 3:24 - loss: 0.3207 - sparse_categorical_accuracy: 0.883 - ETA: 3:24 - loss: 0.3206 - sparse_categorical_ - ETA: 3:23 - loss: 0.3204 - sparse_categorical_accuracy: 0.883 - ETA: 3:23 - loss: 0. - ETA: 3:20 - loss: 0.3204 - sparse_categorical_accuracy: 0 - ETA: 3:20 - loss: 0.3205 - sparse_categorical_accuracy: 0.88 - ETA: 3:20 - loss: 0.3204 - sparse_categorical_ac - ETA: 3:19 - loss: 0.3209 - sparse_categorical - ETA: 3:18 - loss: 0.3204 - sparse_categorical_accura - ETA: 3:18 - loss: 0.3203 - sparse_categorical_accuracy: 0 - ETA: 3:18 - loss: 0.3199 - sparse_categorical_accuracy: 0 - ETA: 3:17 - loss: 0.3201 - sparse_categorical_accuracy: 0 - ETA: 3:17 - loss: 0.3199 - sparse_categorical_accur - ETA: 3:16 - loss: 0.3205 - sparse_categorical_accura - ETA: 3:16 - loss: 0.3203 - sparse_categorical_acc - ETA: 3:15 - loss: 0.3203 - sparse_categorical_accuracy: 0.88 - ETA: 3:15 - loss: 0.3205 - sparse_categorica - ETA: 3:14 - loss: 0.3204 - sparse_categorical_accuracy: 0. - ETA: 3:14 - loss: 0.3202 - sparse_categorical_accuracy: 0.88 - ETA: 3:14 - loss: 0.3201 - sparse_categorical_ac - ETA: 3:13 - loss: 0.3203 - sparse_catego - ETA: 3:11 - loss: 0.3205 - sparse_categorical_accuracy: 0.883 - ETA: 3:11 - loss: 0.3203 - sparse_categorical_accur - ETA: 3:11 - loss: 0.3202 - sparse_categorical_accuracy: 0.88 - ETA: 3:11 - loss: 0.3201 - sparse_categorical_accuracy:  - ETA: 3:11 - loss: 0.3203 - sparse_categorical_accura - ETA: 3:10 - loss: 0.3202 - sparse_categorical_accuracy: 0.88 - ETA: 3:10 - loss: 0.3201 - sparse_categorical_accur - ETA: 3:09 - loss: 0.3203 - sparse_categorical_acc - ETA: 3:08 - loss: 0.3202 - sparse_categorical_accurac - ETA: 3:08 - loss: 0.3202 - sparse_categorical_accuracy: 0 - ETA: 3:07 - loss: 0.3203 - sparse_categorical_accuracy - ETA: 3:07 - loss: 0.3203 - sparse_categorical_accuracy: 0.8 - ETA: 3:07 - loss: 0.3202 - sparse_categorical_accu - ETA: 3:06 - loss: 0.3201 - sparse_categorical_a - ETA: 3:05 - loss: 0.3201 - sparse_categorical_acc - ETA: 3:04 - loss: 0.3199 - sparse_categorical_a - ETA: 3:03 - loss: 0.3199 - sparse_categorical_accuracy: 0 - ETA: 3:03 - loss: 0. - ETA: 3:00 - loss: 0.3197 - sparse_categorical_accuracy: 0.88 - ETA: 3:00 - loss: 0.3197 - sparse_categorical_accuracy: 0.88 - ETA: 3:00 - loss: 0.3197 - sparse_categorical_accu - ETA: 3:00 - loss: 0.3198 - sparse_categorical_accuracy: 0.88 - ETA: 2:59 - loss: 0.3199 - sparse_categorical_accuracy: 0.88 - ETA: 2:59 - loss: 0.3198 - sparse_categorical_acc - ETA: 2:59 - loss: 0.3198 - sparse_categorical_accu - ETA: 2:58 - loss: 0.3197 - sparse_categorical_accuracy: - ETA: 2:57 - loss: 0.3197 - sparse_categorical_accuracy: 0.88 - ETA: 2:57 - loss: 0.3197 - sparse_categorical_accura - ETA: 2:57 - loss: 0.3197 - sparse_categorical_ac - ETA: 2:56 - loss: 0.3198 - sparse_categorical_accu - ETA: 2:55 - loss: 0.3198 - sparse_categorical_accuracy: 0.88 - ETA: 2:55 - loss: 0.3198 - sparse_categor - ETA: 2:54 - loss: 0.3199 - sparse_categorical_accu - ETA: 2:53 - loss: 0.3199 - sparse_categorical_accura - ETA: 2:52 - loss: 0.3201 - sparse_categori - ETA: 2:51 - loss: 0.3200 - sparse_categorical_accuracy: 0.88 - ETA: 2:51 - loss: 0.3201 - sparse_categorical_accuracy: 0.88 - ETA: 2:51 - loss: 0.3201 - sparse_categorical_accura - ETA: 2:50 - loss: 0.3203 - sparse_categoric - ETA: 2:50 - loss: 0.3203 - sparse_categorical_accuracy: 0.8 - ETA: 2:50 - loss: 0.3202 - sparse_categorical_accuracy - ETA: 2:50 - loss: 0.3203 - sparse_categorical_accur - ETA: 2:49 - loss: 0.3201 - sparse_categorical_accuracy: 0.88 - ETA: 2:49 - loss: 0.3201 - sparse_categorical_accuracy: 0.883 - ETA: 2:49 - loss: 0.3201 - sparse_categorical_accur - ETA: 2:48 - loss: 0.3202 - sparse_categorical_acc - ETA: 2:48 - loss: 0.3201 - sparse_categorical_ - ETA: 2:47 - loss: 0.3202 - sparse_categorical_accuracy: - ETA: 2:46 - loss: 0.3201 - sparse_categorical_accuracy: 0. - ETA: 2:46 - loss: 0.3201 - sparse_cate - ETA: 2:45 - loss: 0.3201 - sparse_categorical_accuracy: 0.88 - ETA: 2:45 - loss: 0.3201 - sparse_categorical_accuracy: 0.8 - ETA: 2:44 - loss: 0.3201 - sparse_categorical_accuracy: 0.88 - ETA: 2:44 - loss: 0.3201 - - ETA: 2:42 - loss: 0.3203 - sparse_categorical_ac - ETA: 2:41 - loss: 0.3202 - sparse_categorical_accuracy:  - ETA: 2:41 - loss: 0.3201 - sparse_categorical_accuracy: 0.88 - ETA: 2:41 - loss: 0.3202 - sparse_categorical_accuracy: 0.883 - ETA: 2:40 - loss: 0.3202 - sparse_categorical_accur - ETA: 2:40 - loss: 0.3201 - sparse_categorical_acc - ETA: 2:39 - loss: 0.3201 - sparse_categorical_acc - ETA: 2:38 - loss: 0.3202 - sparse_categorical_accurac - ETA: 2:38 - loss: 0.3202 - sparse_categorica - ETA: 2:37 - loss: 0.3201 - spars - ETA: 2:34 - loss: 0.3202 - sparse_categorical_accuracy: 0.8 - ETA: 2:34 - loss: 0.3201 - sparse_categorical_accuracy: 0.88 - ETA: 2:34 - loss: 0.3202 - sparse_categorical - ETA: 2:33 - loss: 0.3201 - sparse_categorical_accuracy: 0.88 - ETA: 2:33 - loss: 0.3201 - sparse_categorical_accuracy: 0.8 - ETA: 2:33 - loss: 0.3201 - sparse_categorical_accuracy: 0.8 - ETA: 2:32 - loss: 0.3200 - sparse_categorical_accuracy: - ETA: 2:32 - loss: 0.3200 - sparse_categorica - ETA: 2:31 - loss: 0.3202 - sparse_categorical_accuracy: 0.88 - ETA: 2:31 - loss: 0.3202 - sparse_categorical_acc - ETA: 2:30 - loss: 0.3201 - sparse_categorical_accuracy:  - ETA: 2:30 - loss: 0.3201 - sparse_categorical_accu - ETA: 2:29 - loss: 0.3200 - sparse_categorical_accuracy: 0.88 - ETA: 2:29 - loss: 0.3200 - sparse_categorical_accuracy: 0 - ETA: 2:28 - loss: 0.3200 - sparse_categori - ETA: 2:27 - loss: 0.3200 - sparse_categorical_accuracy: 0.88 - ETA: 2:27 - loss: 0.3200 - sparse_categorical_accuracy: 0.88 - ETA: 2:27 - loss: - ETA: 2:24 - loss: 0.3199 - sparse_categorical_accuracy: 0.88 - ETA: 2:24 - loss: 0.3199 - sparse_categorical_accuracy: 0 - ETA: 2:24 - loss: 0.3199 - sparse_categori - ETA: 2:23 - loss: 0.3199 - spar - ETA: 2:21 - loss: 0.3199 - sparse_categorical_accuracy: 0. - ETA: 2:21 - loss: 0.3199 - sparse_categorical_accuracy: 0.88 - ETA: 2:21 - loss: 0.3199 - spar - ETA: 2:19 - loss: 0.3198 - sparse_categorical_accuracy: 0.88 - ETA: 2:19 - loss: 0.3198 - sparse_categorical_ - ETA: 2:18 - loss: 0.3198 - sparse_categorical_accuracy: 0.88 - ETA: 2:18 - loss: 0.3198 - sparse_categorical_accuracy: 0. - ETA: 2:17 - loss: 0.3199 - sparse_categorical_accuracy: 0.884 - ETA: 2:17 - loss: 0.3199 - sparse_categorical_accuracy: 0.884 - ETA: 2:17 - loss: 0.3198 - sparse_categorical_ac - ETA: 2:17 - loss: 0.3197 - sparse_categorical_accuracy: 0.88 - ETA: 2:16 - loss: 0.3198 - sparse_categorical_accuracy: 0. - ETA: 2:16 - loss: 0.3198 - sparse_categorical_accuracy: 0.88 - ETA: 2:16 - loss: 0.3198 - sparse_categorical_a - ETA: 2:15 - loss: 0.3198 - sparse_categorical_acc - ETA: 2:14 - loss: 0.3198 - sparse_categorical_accuracy: 0.88 - ETA: 2:14 - loss: 0.3198 - sparse_categorica - ETA: 2:13 - loss: 0.3197 - sparse_categorical_accuracy: 0.8 - ETA: 2:13 - loss: 0.3197 - sparse_categorical_acc - ETA: 2:12 - loss: 0.3198 - sparse_categorical_accuracy: - ETA: 2:12 - loss: 0.3197 - sparse_categ - ETA: 2:11 - loss: 0.3198 - sparse_categor - ETA: 2:09 - loss: 0.3197 - sparse_categorical_accuracy: 0.88 - ETA: 2:09 - loss: 0.3197 - sparse_categorical_accuracy: 0.88 - ETA: 2:09 - loss: 0.3197 - sparse_categorical_accuracy: 0.88 - ETA: 2:09 - loss: 0.3197 - sparse_categorical_accuracy: 0.88 - ETA: 2:09 - loss: 0.3196 - sparse_categorical_accu - ETA: 2:08 - loss: 0.3197 - sparse_categorical_accu - ETA: 2:07 - loss: 0.3197 - sparse_categorical_accuracy: 0. - ETA: 2:07 - loss: 0.3197 - sparse_categorical_accuracy: 0 - ETA: 2:07 - loss: 0.3196 - sparse_categorical_ac - ETA: 2:06 - loss: 0.3197 - sparse_categorical_accu - ETA: 2:05 - loss: 0.3197 - sparse_categorica - ETA: 2:04 - loss: 0.3196 - sparse_categorical_accurac - ETA: 2:04 - loss: 0.3196 - sparse_categorical_accuracy: 0.88 - ETA: 2:03 - loss: 0.3197 - sparse_c - ETA: 2:02 - loss: 0.3196 - sparse_categorical_accuracy: 0.8 - ETA: 2:02 - loss: 0.3196 - sparse_categorical_accuracy: 0.88 - ETA: 2:02 - loss: 0.3196 - sparse_categorical_a - ETA: 2:01 - loss: 0.3196 - sparse_categorical_accuracy: 0 - ETA: 2:00 - loss: 0.3196 - sparse_categorical_accura - ETA: 2:00 - loss: 0.3196 - sparse_categorical_accuracy: 0.88 - ETA: 2:00 - loss: 0.3196 - sparse_categorical_accuracy: - ETA:  - ETA: 1:56 - loss: 0.3195 - sparse_categorical_accuracy: 0.88 - ETA: 1:56 - loss: 0.3195 - sparse_categorical_acc - ETA: 1:55 - loss: 0.3195 - sparse_categorical_accuracy: 0.8 - ETA: 1:55 - loss: 0.3195 - sparse_categorical_accuracy - ETA: 1:54 - loss: 0.3195 - sparse_categorical_accu - ETA: 1:54 - loss: 0.3196 - sparse_categorical_accuracy: - ETA: 1:53 - loss: 0.3195 - sparse_ca - ETA: 1:52 - loss: 0.3195 - sparse_categorical_accuracy: - ETA: 1:52 - loss: 0.3195 - sparse_categorical_accuracy: 0.88 - ETA: 1:51 - loss: 0.3195 - sparse_categorical_a - ETA: 1:51 - loss: 0.3196 - sparse_categorical_accuracy: 0.884 - ETA: 1:51 - loss: 0.3196  - ETA: 1:49 - loss: 0.3195 - sparse_categorical_accuracy: 0.88 - ETA: 1:49 - loss: 0.3195 - sparse_categorical_accuracy: 0.88 - ETA: 1:49 - loss: 0.3195 - sparse_categorical_accuracy:  - ETA: 1:49 - loss: 0.3195 - sparse_categorical_accuracy - ETA: 1:48 - loss: 0.3196 - sparse_categorical_accurac - ETA: 1:48 - loss: 0.3195 - sparse_categorical_ac - ETA: 1:47 - loss: 0.3194 - sparse_categorical_accuracy: 0.88 - ETA: 1:47 - loss: 0.3195 - sparse_categorical_accuracy: 0.88 - ETA: 1:47 - loss: 0.3195 - sparse_categorical_accuracy: 0.88 - ETA: 1:47 - loss: 0.3195 - sparse_categorical_accuracy: 0.884 - ETA: 1:47 - loss: 0.3195 - sparse_categorical_ac - ETA: 1:46 - loss: 0.3194 - sparse_categorical_accuracy: 0.88 - ETA: 1:46 - loss: 0.3194 - sparse_categorical_accuracy: 0.88 - ETA: 1:46 - loss: 0.3194 - sparse_categorical_accuracy - ETA: 1:45 - loss: 0.3194 - sparse_ - ETA: 1:43 - loss: 0.3193 - sparse_categorical_accuracy: 0. - ETA: 1:43 - loss: 0.3193 - sparse_categorical_accuracy: 0.88 - ETA: 1:43 - loss: 0.3193 - sparse_categorica - ETA: 1:42 - loss: 0.3193 - sparse_categorical_accuracy: 0.8 - ETA: 1:42 - loss: 0.3193 - sparse_categorical_accuracy: 0.88 - ETA: 1:42 - loss: 0.3193 - sparse_categorical_accurac - ETA: 1:41 - loss: 0.3192 - sparse_categorical_accuracy: 0.88 - ETA: 1:41 - loss: 0.3193 - sparse_categorical_accuracy: 0.88 - ETA: 1:41 - loss: 0.3193 - spars - ETA: 1:39 - loss: 0.3193 - sparse_categorical_accuracy: 0.88 - ETA: 1:39 - loss: 0.3193 - sparse_categorical_accuracy: 0.884 - ETA: 1:39 - loss: 0.3193 - sparse_categorical_ac - ETA: 1:38 - loss: 0.3193 - sparse_categorical_accuracy: 0.88 - ETA: 1:38 - loss: 0.3193 - sparse_categorical_accuracy: 0.88 - ETA: 1:38 - loss: 0.3192 - sparse_categorical_accuracy: 0 - ETA: 1:38 - loss: 0.3193 - sparse_categorical_acc - ETA: 1:37 - loss: 0.3192 - sparse_categorical_accurac - ETA: 1:36 - loss: 0.3192 - sparse_categorical_accuracy: 0.88 - ETA: 1:36 - loss: 0.3192 - sparse_categorical_accuracy: 0.88 - ETA: 1:36 - loss: 0.3192 - sparse_categorical_accur - ETA: 1:35 - loss: 0.3192 - sparse_categorical_accuracy: 0.88 - ETA: 1:35 - loss: 0.3192 - sparse_categorical_acc - ETA: 1:35 - loss: 0.3192 - sparse_categorical_accuracy: 0. - ETA: 1:34 - loss: 0.3192 - sparse_categorical_accur - ETA: 1:34 - loss: 0.3192 - sparse_categorical_accuracy: 0.8 - ETA: 1:33 - loss: 0.3192 - sparse_categorical_accuracy: 0. - ETA: 1:33 - loss: 0.3192 - sparse_categorical_acc - ETA: 1:32 - loss: 0.3192 - sparse_categorical_accuracy: 0 - ETA: 1:32 - loss: 0.3191 - sparse_categorical_accura - ETA: 1:32 - loss: 0.3191 - sparse_categorica - ETA: 1:31 - loss: 0.3192 - sparse_categori - ETA: 1:29 - loss: 0.3193 - sparse_categorical_accuracy:  - ETA: 1:29 - loss: 0.3192 - sparse_categorical_accuracy - ETA: 1:29 - loss: 0.3192 - sparse_categorical_accuracy: 0.88 - ETA: 1:29 - loss: 0.3192 - sparse_categorical_accuracy: 0.88 - ETA: 1:28 - loss: 0.3193 - spars - ETA: 1:27 - loss: 0.3193 - sparse_categorical_accuracy: 0.8 - ETA: 1:26 - loss: 0.3193 - sparse_categorical_accuracy: 0.8 - ETA: 1:26 - loss: 0.3193 - sparse_categorical_a - ETA: 1:25 - loss: 0.3192 - sparse_categorical_accuracy: 0.8 - ETA: 1:25 - loss: 0.3193 - sparse_categorical_ - ETA: 1:24 - loss: 0.3192 - sparse_categorical_accuracy: 0.884 - ETA: 1:24 - loss: 0.3192 - sparse_categorical_a - ETA: 1:23 - loss: 0.3192 - sparse_categorical_accuracy: 0 - ETA: 1:23 - loss: 0.3192 - sparse_categorical_accuracy: 0.88 - ETA: 1:23 - loss: 0.3192 - sparse_categorical_accuracy: 0.88 - ETA: 1:23 - loss: 0.3192 - sparse_categorical_accuracy: 0.88 - ETA: 1:23 - loss: 0.3192 - sparse_categorical_accuracy: 0.88 - ETA: 1:23 - loss: 0.3192 - sparse_categorical_accurac - ETA: 1:22 - loss: 0.3193 - sparse_categorical_ - ETA: 1:21 - loss: 0.3192 - sparse_categorical_accuracy: 0.88 - ETA: 1:21 - loss: 0.3192 - sparse_categorical_accuracy: 0.88 - ETA: 1:21 - loss: 0.3192 - sparse_categorical_accuracy: 0.88 - ETA: 1:21 - loss: 0.3192 - sparse_categorical_accur - ETA: 1:20 - loss: 0.3192 - sparse_categorical_accuracy: - ETA: 1:20 - loss: 0.3192 - sparse_categorical_ - ETA: 1:19 - loss: 0.3192 - sparse_categorical_accuracy - ETA: 1:19 - loss: 0.3192 - sparse_categorical_accurac - ETA: 1:18 - loss: 0.3192 - sparse_categorical_accurac - ETA: 1:17 - loss: 0.3192 - sparse_categorical_accuracy: 0.88 - ETA: 1:17 - loss: 0.3192 - sparse_categorical_accuracy: 0. - ETA: 1:17 - loss: 0.3192 - sparse_cat - ETA: 1:16 - loss: 0.3192 - sparse_categorical_accuracy: 0.8 - ETA: 1:15 - loss: 0.3192 - sparse_categorical_accuracy: 0 - ETA: 1:15 - loss: 0.3192 - sparse_categorical_accur - ETA: 1:14 - loss: 0.3192 - sparse_categorical_accuracy: 0.8 - ETA: 1:14 - loss: 0.3192 - sparse_categorical_ac - ETA: 1:13 - loss: 0.3192 - sparse_categori - ETA: 1:12 - loss: 0.3192 - sparse_categoric - ETA: 1:11 - loss: 0.3192 - sparse_categorical_accura - ETA: 1:11 - loss: 0.3192 - sparse_categorical_ac - ETA: 1:10 - loss: 0.3191 - sparse_categorical_accuracy:  - ETA: 1:09 - loss: 0.3191 - sparse_categorical_ac - ETA: 1:08 - loss: 0.3192 - sparse_categorical_accurac - ETA: 1:08 - loss: 0.3192 - sparse_categorical_accuracy: 0 - ETA: 1:08 - loss: 0.3191 - sparse_categorical_accuracy: 0. - ETA: 1:07 - loss: 0.3191 - sparse_categorical_accurac - ETA: 1:07 - loss: 0.3192 - sparse_categorical_acc - ETA: 1:06 - loss: 0.3191 - sparse_categorical_accuracy: 0.88 - ETA: 1:06 - loss: 0.3191 - sparse_categorical_accu - ETA: 1:05 - loss: 0.3191 - sparse_categorical_accuracy: 0.884 - ETA: 1:05 - loss: 0.3192  - ETA: 1:03 - loss: 0.3191 - sparse_categorical_accurac - ETA: 1:03 - loss: 0.3191 - sparse_categorical_accuracy - ETA: 1:02 - loss: 0.3191 - sparse_categorical_accuracy: 0.88 - ETA: 1:02 - loss: 0.3190 - sparse_categorical_accu - ETA: 1:01 - loss: 0.3190 - sparse_categorical_a - ETA: 1:00 - loss: 0.3190 - sparse_categorical_acc - ETA: 1:00 - loss: 0.3190 - sparse_categorical_accuracy: - ETA: 59s - loss: 0.3190 - sparse_categorical_accuracy:  - ETA: 59s - loss: 0.3190 - sparse_categorical_accuracy - ETA: 59s - loss: 0.3190 - sparse_categorical_accuracy:  - ETA: 59s - loss: 0.3189 - sparse_categorical_accu - ETA: 58s - loss: 0.3189 - spa - ETA: 58s - loss: 0.3190 - sparse_categorical_accuracy:  - ETA: 57s - loss: 0.3189 - sparse_cate - ETA: 57s - loss: 0.3190 - sparse_categorical_accuracy: 0. - ETA: 57s - loss: 0.3190 - sparse_categorical_accuracy:  - ETA: 56s - loss: 0.3190 - sparse_catego - ETA: 56s - loss: 0.3189 - sparse_categorical_ac - ETA: 55s - loss - ETA: 54s - loss: 0.3189 - sparse_categorical_ - ETA: 54s - loss: 0.3189 - sparse_categorical_accuracy:  - ETA: 53s - loss: 0.3189 - sparse_categorical_accuracy: 0. - ETA: 53s - loss: 0.3189 - sparse_categorical_accuracy:  - ETA: 53s - loss: 0.3189 - sparse_categori - ETA: 53s - loss: 0.3190 - spa - ETA: 52s - loss: 0.3189 - sparse_categorical_accuracy: 0. - ETA: 52s - loss: 0.3190 - sparse_categorical_accuracy:  - ETA: 51s - loss: 0.3189 - sparse_categorical_accuracy - ETA: 51s - loss: 0.3189 - s - ETA: 50s - loss: 0.3189 - sparse_ca - ETA: 50s - loss: 0.3189 - sparse_categorical_accuracy: 0. - ETA: 50s - loss: 0.3189 - sparse_categori - ETA: 47s - loss: 0.3189 - sparse_categorical_accura - ETA: 47s - loss: 0.31 - ETA: 46s - loss: 0.3189 - sparse_categorical_accuracy: 0. - ETA: 45s - loss: 0.3189 - sparse_categorical_accuracy: 0. - ETA: 45s - loss: 0.3189 - s - ETA: 44s - loss: 0.3189 - sparse_categorica - ETA: 44s - loss: 0.3189 - ETA: 43s - loss: 0.3188 - sparse_categorical_accuracy: 0.88 - ETA: 43s - loss: 0.3188 - ETA: 42s - loss: 0.3188 - sparse_categorical_accuracy: 0. - ETA: 42s - loss: 0.3188 - sparse_categorical_accuracy: 0.88 - ETA: 41s - loss: 0.3188 - sparse_cate - ETA: 41s - loss: 0.3188 - sparse_categorical_accuracy: 0. - ETA: 41s - loss: 0.3188 - sparse_categorical_accuracy: 0. - ETA: 41s - loss: 0.3188 - sparse_categorical_accuracy: 0. - ETA: 40s - loss: 0.3188 - sparse_cate - ETA: 40s - loss: 0.3188 - spars - ETA: 39s - loss: 0.3188 - spa - ETA: 38s -  - ETA: 36s - loss: 0.3188 - sparse_categorical_accuracy:  - ETA: 36s - loss: 0.3188 - sparse_categorica - ETA: 36s - loss: 0.3188 - sparse_categorical_accuracy: 0. - ETA: 36 - ETA: 34s - loss: 0.3188 - sparse_categorical_accuracy: 0.88 - ETA: 34s - loss: 0.3188 - sparse_cate - ETA: 33s - loss: 0.3188 - sparse_categorical_accuracy: 0. - ETA: 33s - loss: 0.3188 - sparse_categorical_accuracy: 0. - ETA: 33s - loss: 0.3188 - sparse_categorica - ETA: 32s - loss: 0.3188 - sparse_categorical_accuracy - ETA: 32s - loss: 0.3188 - sparse_categorical_accu - ETA: 32s - loss: 0.3188 - spars - ETA: 31s - loss: 0.3187 - sparse_catego - E - ETA: 28s - loss: 0.3187 - sparse_cate - ETA: 28s - loss: 0.3187 - sparse_categorical_accuracy:  - ETA: 28s - loss: 0.3187 - s - ETA: 27s - loss: 0.3187 - sparse_categorical_accuracy: 0.88 - ETA: 27s - loss: 0.3187 - sparse_categorical_ac - ETA: 26s - loss: 0.3187 - sparse_categorical_accuracy: 0. - ETA: 26s - loss: 0.3187 - sparse_categori - ETA: 25s - loss: 0.3187 - sparse_categorical_accuracy: 0. - ETA: 25s - loss: 0.3187 - sparse_categorica - ETA: 25s - loss: 0.3187 - sparse_categorical_ - ETA: 24s -  - ETA: 23s - loss: 0.3187 - ETA: 22s - loss: 0.3186 - sparse_ - ETA: 21s - loss: 0.3187 - sparse_categorical_accuracy: 0. - ETA: 21s - loss: 0.3187 - spars - ETA: 20s - loss: 0.3186 - sparse_categorical_accuracy: 0. - ETA: 20s - loss: 0.3186 - sparse_categorical_accura - ETA: 19s - loss: 0.3186 - sparse_catego - ETA: 19s - loss: 0.3186 - sparse_ - ETA: 18s - loss: 0.3185 - sparse_categorical_accuracy: 0. - ETA: 18s - loss: 0.3186 - sparse_categorical_accuracy: 0. - ETA: 18s - loss: 0.3186 - sparse_categorical_ac - ETA: 17s - loss: 0.3186 - sparse_cate - ETA: 17s -  - ETA: 15s - loss: 0.3185 - sparse_categorical_accura - ETA: 15s - loss: 0.3185 - sparse_categorical_accuracy: 0. - ETA: 15s - loss: 0.3185 - sparse_categorical_accura - ETA: 14s - loss: 0.3185 - spars - ETA: 13s - loss: 0.3184 - spars - ETA: 13s - lo - ETA: 11s - loss: 0.3185 - sparse_categorical_ac - ETA: 11s - loss: 0. - ETA: 9s - loss: 0.3185 - sparse_categorical_accuracy: 0. - ETA: 9s - loss: 0.3185 - sparse_categorical_accuracy: 0.8 - ETA: 9s - loss: 0.3185 - sparse_categorical - ETA: 8s - loss: 0.3185 - sparse_categorical_accuracy: 0. - ETA: 8s - loss: 0.3185 - sparse_categorical_accurac - ETA: 7s - loss: 0.3185 - sparse_categorical_accuracy: 0.88 - ETA: 7s - loss: 0.3185 - sparse_categorical_accuracy: 0.8 - ETA: 7s - loss: 0.3185 - sparse_categorical_accuracy: 0.88 - ETA: 7s - loss: 0.3184 - sparse_categor - ETA: 5s - loss: 0.3185 - sparse_categorical_acc - ETA: 5s - loss: 0.3185 - sparse_categorical_accurac - ETA: 4s - loss: 0.3185 - sparse_categorical_accuracy: 0 - ETA: 4s - loss: 0.3185 - sparse_categorical_accuracy: 0.8 - ETA: 4s - loss: 0.3185 - sparse_categorica - ETA: 2s - loss: 0.3185 - sparse_ca - ETA: 1s - loss: 0.3185 - sparse_categorical_accuracy: 0 - ETA: 1s - loss: 0.3184 - sparse_categorical_accuracy - ETA: 0s - loss: 0.3184 - sparse_categorical_accuracy: 0.8 - ETA: 0s - loss: 0.3184 - sparse_categorical_accur\n",
      "\n",
      "Epoch 00010: sparse_categorical_accuracy improved from 0.88255 to 0.88429, saving model to train/run_local/ckpt/weights-10-0.8843.h5\n",
      "2022/05/17 22:16:54 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: 'PrefetchDataset' object has no attribute '_batch_size'\n",
      "{'loss': [0.49531111121177673, 0.3774506151676178, 0.3674352169036865, 0.3585301637649536, 0.34999603033065796, 0.34330302476882935, 0.3358615040779114, 0.3297356963157654, 0.32416102290153503, 0.31841185688972473], 'sparse_categorical_accuracy': [0.8154379725456238, 0.8633173108100891, 0.8665599822998047, 0.8701186776161194, 0.873171329498291, 0.8752279877662659, 0.8783693313598633, 0.8804073333740234, 0.8825520277023315, 0.8842893242835999], 'val_loss': [0.35785502195358276, 0.3493979573249817, 0.34133684635162354, 0.33523842692375183, 0.3292787969112396, 0.3232123851776123, 0.3176858425140381, 0.31336039304733276, 0.3100125193595886, 0.30586686730384827], 'val_sparse_categorical_accuracy': [0.8700000047683716, 0.8715384602546692, 0.8730769157409668, 0.8730769157409668, 0.873846173286438, 0.876153826713562, 0.8799999952316284, 0.881538450717926, 0.8838461637496948, 0.8853846192359924]}\n",
      "Figure(640x480)\n"
     ]
    }
   ],
   "source": [
    "# !python ../discard/keras_rewrite/train.py \\\n",
    "# --data_dir={DATASET_DIR} \\\n",
    "# --wanted_words={WANTED_WORDS} \\\n",
    "# --silence_percentage={SILENT_PERCENTAGE} \\\n",
    "# --unknown_percentage={UNKNOWN_PERCENTAGE} \\\n",
    "# --preprocess={PREPROCESS} \\\n",
    "# --window_stride={WINDOW_STRIDE} \\\n",
    "# --model_architecture={MODEL_ARCHITECTURE} \\\n",
    "# --how_many_training_steps={TRAINING_STEPS} \\\n",
    "# --learning_rate={LEARNING_RATE} \\\n",
    "# --train_dir={TRAIN_DIR} \\\n",
    "# --summaries_dir={LOGS_DIR} \\\n",
    "# --verbosity={VERBOSITY} \\\n",
    "# --eval_step_interval={EVAL_STEP_INTERVAL} \\\n",
    "# --save_step_interval={SAVE_STEP_INTERVAL} \\\n",
    "# --no_mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQUJLrdS-ftl"
   },
   "source": [
    "## Generate a TensorFlow Model for Inference\n",
    "\n",
    "Combine relevant training results (graph, weights, etc) into a single file for inference. This process is known as freezing a model and the resulting model is known as a frozen model/graph, as it cannot be further re-trained after this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xyc3_eLh9sAg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 15:59:09.095663: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "2022-06-20 15:59:09.095782: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "2022-06-20 15:59:09.122774: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "2022-06-20 15:59:10.835352: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-20 15:59:10.839897: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "None\n",
      "Saving to file models/saved_model\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2022-06-20 15:59:11.159383: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "# !rm -rf {SAVED_MODEL}\n",
    "!python ./utils/keras_rewrite/freeze.py \\\n",
    "--wanted_words={WANTED_WORDS} \\\n",
    "--model_architecture={MODEL_ARCHITECTURE} \\\n",
    "--load_weights=./train/run_local/ckpt/weights-10-0.8843.h5 \\\n",
    "--output={SAVED_MODEL} \\\n",
    "--input_shape='(1960)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_DBGDxVI-nKG"
   },
   "source": [
    "## Generate a TensorFlow Lite Model\n",
    "\n",
    "Convert the frozen graph into two TensorFlow Lite model. The first one is without quantization \"Float_Model\". The second one is fully quantized for use with embedded devices. \n",
    "\n",
    "The following cell will also print the model size, which will be under 20 kilobytes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Float TFlite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-17 22:46:02.416449: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "2022-05-17 22:46:02.416589: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "2022-05-17 22:46:02.525551: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "2022-05-17 22:46:04.292657: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-17 22:46:04.293856: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-05-17 22:46:04.516230: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.\n",
      "2022-05-17 22:46:04.516278: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored drop_control_dependency.\n",
      "2022-05-17 22:46:04.516293: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored change_concat_input_ranges.\n",
      "2022-05-17 22:46:04.517401: I tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: models/saved_model\n",
      "2022-05-17 22:46:04.520595: I tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }\n",
      "2022-05-17 22:46:04.520639: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: models/saved_model\n",
      "2022-05-17 22:46:04.520726: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-05-17 22:46:04.525782: I tensorflow/cc/saved_model/loader.cc:211] Restoring SavedModel bundle.\n",
      "2022-05-17 22:46:04.548112: I tensorflow/cc/saved_model/loader.cc:195] Running initialization op on SavedModel bundle at path: models/saved_model\n",
      "2022-05-17 22:46:04.554008: I tensorflow/cc/saved_model/loader.cc:283] SavedModel load for tags { serve }; Status: success: OK. Took 36610 microseconds.\n",
      "2022-05-17 22:46:04.573612: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-05-17 22:46:04.590866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-05-17 22:46:04.605242: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1899] Estimated count of arithmetic ops: 0.676 M  ops, equivalently 0.338 M  MACs\n",
      "Exported float model: 68596 bytes\n"
     ]
    }
   ],
   "source": [
    "# write the float tflite model\n",
    "!python ./utils/keras_rewrite/generate_tflite.py \\\n",
    "--input={SAVED_MODEL}  \\\n",
    "--output={FLOAT_MODEL_TFLITE} \\\n",
    "--cfile "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantized TFlite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-17 22:47:54.553288: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "2022-05-17 22:47:54.553417: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "2022-05-17 22:47:54.589940: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "2022-05-17 22:47:56.125178: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-17 22:47:56.127890: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-05-17 22:47:56.322763: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.\n",
      "2022-05-17 22:47:56.322808: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored drop_control_dependency.\n",
      "2022-05-17 22:47:56.322819: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored change_concat_input_ranges.\n",
      "2022-05-17 22:47:56.323968: I tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: models/saved_model\n",
      "2022-05-17 22:47:56.327625: I tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }\n",
      "2022-05-17 22:47:56.327664: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: models/saved_model\n",
      "2022-05-17 22:47:56.327755: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-05-17 22:47:56.332662: I tensorflow/cc/saved_model/loader.cc:211] Restoring SavedModel bundle.\n",
      "2022-05-17 22:47:56.357962: I tensorflow/cc/saved_model/loader.cc:195] Running initialization op on SavedModel bundle at path: models/saved_model\n",
      "2022-05-17 22:47:56.363366: I tensorflow/cc/saved_model/loader.cc:283] SavedModel load for tags { serve }; Status: success: OK. Took 39402 microseconds.\n",
      "2022-05-17 22:47:56.374939: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-05-17 22:47:56.390781: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-05-17 22:47:56.410423: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1899] Estimated count of arithmetic ops: 0.676 M  ops, equivalently 0.338 M  MACs\n",
      "Gathering .wav files from dataset/ : 100it [00:00, 297257.55it/s]\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 9, output_inference_type: 9\n",
      "2022-05-17 22:48:18.882166: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1899] Estimated count of arithmetic ops: 0.676 M  ops, equivalently 0.338 M  MACs\n",
      "Exported quantized model: 19216 bytes\n"
     ]
    }
   ],
   "source": [
    "# write the quantized model\n",
    "!python ./utils/keras_rewrite/generate_tflite.py \\\n",
    "--input={SAVED_MODEL} \\\n",
    "--output={MODEL_TFLITE} \\\n",
    "--int_only \\\n",
    "--data_dir={DATASET_DIR} \\\n",
    "--preprocess={PREPROCESS} \\\n",
    "--window_stride={WINDOW_STRIDE} \\\n",
    "--cfile "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_micro_speech_model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.6-cpu-py38-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
